%% Template for a scientific paper by Samuel Pawel
%% Last modification: 17. December 2020
\documentclass[a4paper, 11pt]{article}
\usepackage{amsmath, amssymb}
\usepackage{doi} % automatic doi-links
\usepackage[round]{natbib} % bibliography
\usepackage{multirow}
\usepackage{booktabs} % nicer tables
\usepackage[title]{appendix} % better appendices
\usepackage{nameref} % reference appendices with names
\usepackage[dvipsnames,table]{xcolor}
%% \usepackage[doublespacing]{setspace} % line spacing
\usepackage[onehalfspacing]{setspace}
\usepackage[labelfont=bf,font=small]{caption} % smaller captions
\usepackage{helvet}
\usepackage{mathpazo}
\usepackage{sectsty} % use different fonts for different sections
\allsectionsfont{\sffamily} % for sections use sans serif
\usepackage[labelfont={bf,sf},font=small]{caption} % customize captions
\usepackage{orcidlink} % for ORCID symbol with link
\definecolor{lightgray}{gray}{0.9}
\usepackage{pifont} % checkmark and cross symbol
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%

% for anonymization
\newif\ifanonymize % Boolean variable to control anonymization
\newcommand{\anonymize}[1]{%
  \ifanonymize
    \phantom{#1}%
  \else
    #1%
  \fi
}
% \anonymizetrue % set to true to anonymize
\anonymizefalse % set to false to deanonymize

%% margins
\usepackage{geometry}
\geometry{
  a4paper,
  total={170mm,257mm},
  left=20mm,
  right=20mm,
  top=30mm,
  bottom=25mm,
}


%% title, authors, affiliations, mail
\newcommand\mail{samuel.pawel@uzh.ch}
\title{\vspace{-4em}
  %\textbf{\textsf{Desert Island Sample Size Calculations for Bayesians}}
  \textbf{\textsf{Closed-Form Power and Sample Size Calculations for Bayes Factors}}
}
\author{
  \anonymize{\textbf{Samuel Pawel} \orcidlink{0000-0003-2779-320X}} \and
  \anonymize{\textbf{Leonhard Held} \orcidlink{0000-0002-8686-5325}}
}
\date{
  \anonymize{Epidemiology, Biostatistics and Prevention Institute (EBPI)} \\
  \anonymize{Center for Reproducible Science (CRS)} \\
  \anonymize{University of Zurich} \\
  \anonymize{E-mail: \href{mailto:\mail}{\mail}} \\[2ex]
  \anonymize{{\color{blue} Preprint version June 28, 2024}}
}

%% hyperref options
%% ----------------------------------------------------------------------------
\usepackage{hyperref}  
\hypersetup{
  bookmarksopen=true, 
  breaklinks=true,
  pdftitle={Closed-Form Power and Sample Size Calculations for Bayes Factors},
  pdfsubject={},
  pdfkeywords={},
  colorlinks=true,
  linkcolor=black,
  anchorcolor=black,
  citecolor=blue,
  urlcolor=blue,
}

%% Headers and footers
%% ----------------------------------------------------------------------------
\usepackage{fancyhdr}
\pagestyle{fancy}
% \lhead{Desert Island Sample Size Calculations for Bayesians}
\lhead{Closed-Form Power and Sample Size Calculations for Bayes Factors}
\rhead{\anonymize{S. Pawel and L. Held}}


<< "main-setup", include = FALSE >>=
## knitr options
library(knitr)
opts_chunk$set(fig.height = 4,
               echo = FALSE,
               warning = FALSE,
               message = FALSE,
               cache = FALSE,
               eval = TRUE)

## should sessionInfo be printed at the end?
Reproducibility <- TRUE

## packages
library(bfpwr)
library(xtable)
library(lamW)
library(BayesRep)
library(BFDA)
@

\begin{document}
\maketitle


% Abstract
% ======================================================================
\begin{abstract}
  \noindent Determining an appropriate sample size is a critical element of study design, and the method used to determine it should be consistent with the planned analysis. When the planned analysis involves Bayes factor hypothesis testing, the sample size is usually desired to ensure a sufficiently high probability of obtaining a Bayes factor indicating compelling evidence for a hypothesis, given that the hypothesis is true. In practice, Bayes factor sample size determination is typically performed using computationally intensive Monte Carlo simulation. Here, we summarize alternative approaches that enable sample size determination without simulation. We show how, under approximate normality assumptions, sample sizes can be determined numerically, and provide the R package \texttt{bfpwr} for this purpose. Additionally, we identify conditions under which sample sizes can even be determined in closed-form, resulting in novel, easy-to-use formulas that also help foster intuition, enable asymptotic analysis, and can also be used for hybrid Bayesian/likelihoodist design. Furthermore, we show how in our framework power and sample size can be computed without simulation for more complex analysis priors, such as Jeffreys-Zellner-Siow priors or nonlocal normal moment priors. Case studies from medicine and psychology illustrate how researchers can use our methods to design informative yet cost-efficient studies.
  \\
  \textit{Keywords:} Bayesian hypothesis testing, evidence, likelihood ratio,
  predictive power, study design
\end{abstract}


% Introduction
% ======================================================================
\section{Introduction}
A key aspect of study design is determining an appropriate sample size. Choosing
a sample size that is too small may lead to inconclusive study results, while
choosing a sample size that is too large may be unethical (e.g., for animal
studies) or waste samples which could be of better use in other studies. Whether
or not a certain sample size can ensure sufficiently conclusive results depends
on the planned analysis. Therefore, the sample size calculation should be
aligned with the planned analysis \citep{Anderson2022}, or in other words:
`\emph{As ye shall analyse is as ye shall design}' \citep[p.~179]{Julious2023}.

A widely used formula for the sample size per group (with two groups of equal
size) for continuous outcome data, based on a frequentist hypothesis test of a
mean difference, is given by
\begin{align}
  \label{eq:freqsamplesize}
  n = \frac{2 \sigma^{2} (z_{1 - \alpha/2} + z_{1 - \beta})^2}{(\mu - \theta_0)^2},
\end{align}
where $z_{q}$ is the $q\times 100\%$ quantile of the standard normal
distribution, $\alpha$ is the level of the test, $1 - \beta$ is the desired
power, $\mu$ is the assumed mean difference, $\theta_0$ is the mean difference
under the null hypothesis, and $\sigma^2$ is the variance of one observation
\citep[p.~34]{Matthews2006}. There exist various refinements
of~\eqref{eq:freqsamplesize}, such as, adaptations to unequal randomization,
special study designs (e.g., cross-over studies), or other data types (e.g.,
binary data), see, for example, \citet{Kieser2020} or \citet{Julious2023}. For
many analysis methods, however, no closed-form formula exist and iterative or
simulation methods have to be used. Nevertheless, while typically only being an
approximation, the formula~\eqref{eq:freqsamplesize} enables quick-and-dirty
calculations that are often accurate enough for practical purposes. It also
helps fostering intuition and is therefore useful, for example, in teaching of
statistics or the study of asymptotics.


An alternative to frequentist hypothesis testing is Bayesian hypothesis testing.
There are different flavors of Bayesian hypothesis testing, one of the most
popular being the approach centered around the \emph{Bayes factor}, which is the
data-based updating factor of the prior to posterior odds of two competing
hypotheses. Bayes factor approaches were pioneered by \citet{Jeffreys1939} and
are now in use in various scientific domains such as medicine
\citep{Goodman1999}, psychology \citep{Wagenmakers2007}, or physics
\citep{Trotta2008}. Bayes factor tests are conceptually different from
frequentist tests in several ways. For example, they can quantify evidence in
favor of a null hypothesis or they can incorporate external information via a
prior distribution. For an overview of Bayes factors see e.g., \citet{Kass1995,
  Held2018}.

Also if Bayes factors are used in the analysis, the design of the study should
match the analysis. Fortunately, there is methodology for design based on Bayes
factors \citep{Weiss1997, Gelfand2002, DeSantis2004, DeSantis2007,
  Schoenbrodt2017, Schnbrodt2017b, Pawel2023e, Stefan2022}. However, to our
knowledge, there are no simple formulas such as~\eqref{eq:freqsamplesize} for
sample size determination based on Bayes factor analyses. In practice, sample
size determination is often performed by Monte Carlo simulation
\citep{Gelfand2002, Schoenbrodt2017, Stefan2022}, but this can be inaccurate,
time-consuming, and less intuitive than a formula.

The goal of this paper is therefore to investigate whether, under approximate
normality assumptions similar to those underlying the
formula~\eqref{eq:freqsamplesize}, a sample size formula can be derived for a
planned Bayes factor analysis. As we will show, the answer is affirmative under
certain assumptions about the analysis prior (the prior distribution for the
parameter used in the analysis) and the design prior (the prior distribution for
the parameter used in the design). A distinction must be made between point
priors and normal priors, both in the design and in the analysis. Point analysis
priors lead to Bayes factors reducing to likelihood ratios, the analysis thereby
corresponding with a frequentist `likelihoodist' analysis \citep{Edwards1971,
  Royall1997, Blume2002, Strug2018}, while point design priors lead to
`conditional power', which corresponds to traditional frequentist power. In
contrast, normal analysis and design priors can account for parameter
uncertainty, producing Bayes factors that differ from likelihood ratios and
`predictive power' that differs from frequentist power \citep[see e.g.,][for
conditional/predictive power related to posterior tail probability
analyses]{OHagan2005, Micheloud2020, Grieve2022}.

Based on the point/normal prior distinction, we find that closed-form sample
sizes are available for Bayes factors with point analysis priors (i.e.,
likelihood ratios) along with point or normal design priors, and for Bayes
factors with local normal analysis and design priors (i.e., normal priors
centered on the null value), see Table~\ref{tab:summary} for an overview of our
results. In addition to our novel formulas, we summarize sample size
determination for Bayes factors with normal priors based on numerical
root-finding \citep[which has done before, e.g., in][]{Weiss1997, Pawel2023e},
and show how it can be extended to more advanced prior distributions, such as
normal moment priors and Jeffreys-Zellner-Siow priors. While root-finding
approaches also do not produce closed-form sample sizes, computations are
deterministic and usually faster than with simulation approaches. To facilitate
reuse of our results, all methods are made available through our R package
\texttt{bfpwr}.

\begingroup
\renewcommand{\arraystretch}{1.3} % Default value: 1
\begin{table}[!htb]
  \centering
  \caption{Availability of closed-form sample size formulas for Bayes factor
    hypothesis test of $H_{0} \colon \theta = \theta_{0}$ against
    $H_{1} \colon \theta \neq \theta_{0}$ with either a point prior or a normal
    analysis prior assigned to $\theta$ under $H_{1}$, and data in the form of a
    normally distributed parameter estimate
    $\hat{\theta} \mid \theta \sim \mathrm{N}(\theta, \sigma_{\scriptscriptstyle \hat{\theta}}^{2}/n)$.
    In all cases, the power can be computed in closed-form.}
  \label{tab:summary}
  {\small
  \begin{tabular}{l c c }
    \toprule
    & \multicolumn{2}{c}{Analysis prior} \\
    \cmidrule{2-3}
    \multicolumn{1}{c}{Design prior} & Point prior (likelihood ratio) & Normal prior (Bayes factor) \\
    % & $\theta = \mu$ & $\theta \sim \mathrm{N}(\mu, \tau^{2})$ \\
    \midrule
    Point prior (conditional power) % $\theta = \mu_{d}$
 &\cellcolor{green!10}  \cmark ~ Equation~\eqref{eq:nLR2} & \cellcolor{red!10} \xmark ~ Unavailable \\
    Normal prior (predictive power) % $\theta \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d})$
    & \cellcolor{green!10} \cmark ~ Equation~\eqref{eq:nLR} & \cellcolor{yellow!10} \cmark ~ Equation~\eqref{eq:nBF} for local normal priors \\
    \bottomrule
  \end{tabular}
  }
\end{table}
\endgroup

This paper is organized as follows: We begin by defining the type of Bayes
factor underlying our sample size calculations (Section~\ref{sec:BF}), followed
by deriving its distribution when new data are generated under various design
priors (Section~\ref{sec:distBF}). Combining these results, we derive several
formulas for the sample size under different constellations of design and
analysis priors (Section~\ref{sec:ssd}). Examples from medicine and psychology
then illustrates how our formulas can be used by researchers in practice
(Section~\ref{sec:application}). Section~\ref{sec:extensions} illustrates
possible extensions of our framework to other popular types of analysis priors,
such as informed $t$ priors \citep{Gronau2020} and nonlocal normal moment priors
\citep{Johnson2010}. The paper ends with a closing discussion of our results and
final remarks on limitations and extensions (Section~\ref{sec:discussion}). Our
R package \texttt{bfpwr} that implements the developed methods is illustrated in
Appendix~\ref{app:pkg}.


\section{Assumed Bayes factor analysis}
\label{sec:BF}
To derive a sample size formula, we must first clarify how the future data will
be analyzed. Denote by $\hat{\theta}$ the estimate of an unknown parameter
$\theta$ that will result from the statistical analysis of $n$ effective future
observations, each with unit variance
$\sigma^2_{\scriptscriptstyle \hat{\theta}}$. Assume that the estimate (but not
necessarily the underlying data) is approximately normally distributed around
$\theta$ with variance $\sigma^2_{\scriptscriptstyle \hat{\theta}}/n$, i.e.,
\mbox{$\hat{\theta} \mid \theta \sim \mathrm{N}(\theta, \sigma^2_{\scriptscriptstyle \hat{\theta}}/n)$}.
Table~\ref{tab:outcomes} shows common types of parameter estimates and the
resulting interpretation of $n$ and the unit variance
$\sigma^2_{\scriptscriptstyle \hat{\theta}}$. It is important to note that these
are only approximations and they may be inadequate in certain situations, such
as small sample sizes or rare events \citep{Spiegelhalter2004}. The frequentist
sample size formula~\eqref{eq:freqsamplesize} can also be cast in this
framework; it assumes continuous outcome data and a mean difference parameter
(second row in Table~\ref{tab:outcomes}). As such, the formula could be
generalized to other settings by replacing $2\sigma^{2}$ in the numerator with
other unit variances from Table~\ref{tab:outcomes}, which would in turn change
the interpretation of $n$ and $\hat{\theta}$.
% However, in the same situations, the standard frequentist sample size
% formula~\eqref{eq:freqsamplesize} also becomes inadequate, since it is based
% on the same assumption of a normally distributed mean difference.

% Finally, in the actual analysis of the data, we may replace
% $ \sigma^2_{\scriptscriptstyle \hat{\theta}}/n$ by the squared standard error
% of the parameter estimate, for example, obtained from an estimated regression
% model, yet in the design we need to assume form for the standard error that
% incorporates the sample size $n$

% For example, the unknown parameter could be the mean difference of an outcome
% among two treatment groups $\theta = \mathrm{E}(Y_{a}) - \mathrm{E}(Y_{b})$,
% which is estimated from the observed mean difference and
% $\hat{\theta} = \bar{y}_{a} - \bar{y}_{b}$. Depending on whether $n$
% represents the total sample size or the sample size per treatment group
% (assuming equal sample size per group), the unit variance differs. For the
% former, we have unit variance
% $\sigma^{2} = 2\{\mathrm{Var}(Y_{a}) + \mathrm{Var}(Y_{b})\}$ while for the
% latter we have $\sigma^{2} = \mathrm{Var}(Y_{a}) + \mathrm{Var}(Y_{b})$.

\begingroup
\renewcommand{\arraystretch}{1.3} % Default value: 1
\begin{table}[!htb]
  \centering
  \caption{Different types of parameter estimates $\hat{\theta}$ with
    approximate variance
    $\mathrm{Var}(\hat{\theta}) = \sigma^2_{\scriptscriptstyle \hat{\theta}}/n$
    and corresponding interpretation of sample size $n$ and unit variance
    $\sigma^2_{\scriptscriptstyle \hat{\theta}}$ (adapted from Chapter 2.4 in
    \citealp{Spiegelhalter2004} and Chapter 1 in \citealp{Grieve2022}). The
    variance of one continuous outcome observation is denoted by $\sigma^{2}$.
    Parameter estimates based on two groups assume an equal number of observations
    per group.}
  \label{tab:outcomes}
  \rowcolors{1}{}{lightgray}
  \begin{tabular}{l l l c}
    \toprule
    \textbf{Outcome} & \textbf{Parameter estimate} $\hat{\theta}$ & \textbf{Interpretation of} $n$ & \textbf{Unit variance} $\sigma^2_{\scriptscriptstyle \hat{\theta}}$ \\
    \midrule
    Continuous & Mean & Sample size & $\sigma^{2}$ \\
    Continuous & Mean difference & Sample size per group & $2\sigma^{2}$ \\
    Continuous & Standardized mean difference & Sample size per group & 2 \\
    Continuous & $z$-transformed correlation & Sample size minus 3 & 1 \\
    Binary & Log odds ratio & Total number of events & 4 \\
    Binary & Arcsine square root difference & Sample size per group & 1/2 \\
    Survival & Log hazard ratio & Total number of events & 4 \\
    Count & Log rate ratio & Total count & 4 \\

    \bottomrule
    \end{tabular}
\end{table}
\endgroup


Assume now a point null hypothesis that postulates that $\theta$ equals a
certain null value \mbox{$H_0 \colon \theta = \theta_0$} and an alternative
hypothesis that postulates that $\theta$ does not equal the null value
$H_1 \colon \theta \neq \theta_0$, with prior
\mbox{$\theta \mid H_1 \sim \mathrm{N}(\mu, \tau^2)$} assigned to $\theta$ under
$H_1$. The mean of the prior $\mu$ determines the most plausible parameter value
under the alternative while the standard deviation $\tau$ determines its
uncertainty. A point alternative at $\mu$ may be obtained by letting the
standard deviation of the prior go to zero. Whenever we write $\tau = 0$, we
informally refer to a point prior at $\mu$, since for all calculations in this
paper this notation leads to the same results as a more formal treatment of
point priors.
% Here and henceforth, we define that whenever $\tau^{2} = 0$, a normal prior is
% equal to a point mass at its mean $\mu$ since for all calculations in this
% paper. , although technically this should be defined via a limit, yet it does
% not matter for the calculations in this paper).
The Bayes factor is then given by the updating factor of the prior to posterior
odds of $H_0$ versus $H_1$, i.e.,
\begin{align}
\label{eq:BF01}
    \text{BF}_{01} 
    = \frac{\Pr(H_0 \mid \hat{\theta})}{\Pr(H_1 \mid \hat{\theta})} \bigg/ \, \frac{\Pr(H_0)}{\Pr(H_1)}
    = \sqrt{1 + \frac{n \tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}} \exp\left[-\frac{1}{2} \left\{\frac{(\hat{\theta} - \theta_0)^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}/n} - \frac{(\hat{\theta} - \mu)^2}{\tau^2 + \sigma^2_{\scriptscriptstyle \hat{\theta}}/n}\right\}\right].
\end{align}
A Bayes factor smaller than one ($\text{BF}_{01} < 1$) indicates evidence for
the alternative hypothesis $H_{1}$, while a Bayes factor greater than one
($\text{BF}_{01} > 1$) indicates evidence for the null hypothesis $H_{0}$. The
larger the deviation of the Bayes factor from one, the stronger the evidence.
The Bayes factor~\eqref{eq:BF01} is implemented in our package in the function
\texttt{bf01}.


The Bayes factor~\eqref{eq:BF01} has already appeared in the literature in one
form or another \citep[e.g., in][]{Weiss1997, DeSantis2004, Spiegelhalter2004,
  Dienes2014, Bartos2023b}, with perhaps the first proposal of a Bayes factor
based on an approximately normally distributed parameter estimate and its
standard error dating back to \citet{Jeffreys1936}, see also
\citet{Wagenmakers2022} for some historical notes on Jeffreys' approach. The
Bayes factor~\eqref{eq:BF01} may be thought of as a `Bayesian \mbox{$z$-test}',
that is, a test of a normal mean based on an asymptotically normal statistic
assuming that the variance of the statistic is known. Of course, the latter
assumption is not true in most applications, but it makes the test widely
applicable and is, for practical purposes, often close enough to Bayes factors
based on the exact distribution of the data, which may or may not be available.
Finally, the Bayes factor~\eqref{eq:BF01} can also be used with parameter
estimates where a standard error is available but not of the form
$\sigma_{\scriptscriptstyle \hat{\theta}}/\sqrt{n}$, e.g., a parameter estimate
from a generalized linear model where the estimate is adjusted for covariates
and the standard error is obtained numerically. In this case,
$\sigma_{\scriptscriptstyle \hat{\theta}}/\sqrt{n}$ in~\eqref{eq:BF01} can be
replaced by the observed standard error. However, as we will show now, assuming
such a particular dependence on the sample size $n$ allows us to perform
closed-form power and sample size calculations under certain additional
assumptions.


\section{Distribution and power function of the Bayes factor}
\label{sec:distBF}
Suppose now that we are interested in finding compelling evidence in favor of
the alternative $H_{1}$ over the null hypothesis $H_{0}$ with a Bayes
factor~\eqref{eq:BF01} smaller than some threshold $k < 1$. For example, the
evidence thresholds could be $k = 1/3$ or $k = 1/10$, the levels from
\citet{Jeffreys1939} for `substantial' and `strong' evidence, respectively. To
determine a sample size that ensures compelling evidence with a desired
probability we need to know the distribution of the Bayes factor~\eqref{eq:BF01}
for a given sample size.

% Assume that new parameter estimates $\hat{\theta}$ are generated from a normal
% distribution with mean $m$ and variance $v$, i.e.,
% $\hat{\theta} \sim \mathrm{N}(m, v)$. This distribution may be induced by a
% for example, a point prior
% $\theta = \mu$ in which case $m = \mu$ and
% $v = \sigma^2_{\scriptscriptstyle \hat{\theta}}/n$, or a normal prior
% $\theta \sim \mathrm{N}(\mu, \tau^2)$ in which case $m = \mu$ and
% $v = \tau^2 + \sigma^2_{\scriptscriptstyle \hat{\theta}}/n$. The design prior
% typically represents the best state of knowledge about $\theta$ at the design
% stage. On the other hand, the `analysis prior' used for the Bayes
% factor~\eqref{eq:BF01} does not necessarily have to be the same as the design
% prior, as the analysis may, for instance, require a certain `default' or
% `objective' prior that is conventionally used in the field.

Assume a so-called `design prior' for the parameter $\theta$ that is used in the
design of the study \citep{OHagan2001b, OHagan2005}. This prior should represent
the state of knowledge and uncertainty about $\theta$ at the design stage and
does not necessarily have to correspond to the `analysis prior'
\mbox{$\theta \mid H_{1} \sim \mathrm{N}(\mu, \tau^{2})$} used for the Bayes
factor~\eqref{eq:BF01}. In fact, the analysis prior is often set to a certain
`default' or `objective' prior that is conventionally used in the field. Here,
we will focus on normal design priors
$\theta \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d})$, as they are flexible enough to
specify varying degrees of uncertainty about the parameter, and at the same time
mathematically convenient for obtaining closed-form solutions for power and, in
some cases, sample size. Point priors, and as such classical sample size
determination with an `assumed parameter', then represent a special case of the
normal prior where the standard deviation becomes infinitesimally small
($\tau_{d} = 0$).

Such a normal design prior induces a predictive distribution
$\hat{\theta} \mid n, \mu_{d} , \tau_{d} \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d} + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n)$
for the future parameter estimate $\hat{\theta}$, which is again a normal
distribution centered around the design prior mean $\mu_{d}$ but with a variance
given by the sum of the squared standard error
$\sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n$ and the design prior variance
$\tau_{d}^{2}$. Under this distribution, the distribution of the Bayes factor
with normal analysis prior~\eqref{eq:BF01} can be derived in closed-form
\citep{Weiss1997, DeSantis2004}. We now rederive and extend this result in our
setting and notation. The two cases of the Bayes factor with $\tau = 0$ (point
analysis prior under the alternative) and $\tau > 0$ (normal analysis prior
under the alternative) need to be distinguished, as the resulting Bayes factor
distributions take a different form, and only the latter has been considered
previously in the Bayes factor literature.

For the Bayes factor with point analysis prior ($\tau = 0$), the cumulative
distribution or `power function' is
\begin{align}
\label{eq:prLR}
  \Pr(\text{BF}_{01} \leq k \mid n, \mu_{d} , \tau_{d}, \tau = 0)
  = \begin{cases}
      1 - \Phi(Z) & \text{if}~ \mu - \theta_0 > 0 \\
      \Phi(Z) & \text{if}~ \mu - \theta_0 < 0
    \end{cases}
\end{align}
with $\Phi(\cdot)$ the standard normal cumulative distribution function and
\begin{align*}
    Z = \frac{1}{\sqrt{\tau^{2}_{d} + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n}}\left\{
    \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}\log k}{n(\theta_0 - \mu)} + \frac{\theta_0 + \mu}{2}
    - \mu_{d}\right\},
\end{align*}
see Appendix~\ref{app:distributions} for details. In standard frequentist sample
size determination, the power can typically be increased arbitrarily close to
one by increasing the sample size.
% (provided the parameter under the alternative $\mu$ differs from the parameter
% under null $\theta_{0}$).
However, with the Bayes factor based on a point analysis prior, depending on the
assumed design prior, one may not be able to approach a power of one with the
power function~\eqref{eq:prLR} by increasing the sample size $n$. That is, the
limiting power value is given by
\begin{align}
  \label{eq:powerlimLR}
  \lim_{n \to \infty} \Pr(\mathrm{BF}_{01} \leq k \mid n, \mu_{d} , \tau_{d}, \tau = 0)
    = \begin{cases}
      1 - \Phi(Z_{\mathrm{lim}}) & \text{if}~ \mu - \theta_0 > 0 \\
      \Phi(Z_{\mathrm{lim}}) & \text{if}~ \mu - \theta_0 < 0
    \end{cases}
\end{align}
with $Z_{\mathrm{lim}} = (\theta_{0} + \mu - 2 \mu_{d})/(2 \tau_{d})$. When the
design prior is also point prior ($\tau_{d} = 0$), $Z_{\mathrm{lim}}$~diverges
and the limiting power~\eqref{eq:powerlimLR} approaches one or zero, depending
on whether the location of the design prior $\mu_{d}$ is closer to the
alternative $\mu$ or to the null $\theta_{0}$. In case it is just in between the
two ($\mu_{d} = (\theta_{0} + \mu)/2$), the limiting power approaches a half. On
the other hand, for a normal design prior ($\tau_{d} > 0$), the limiting power
is bounded by a value in between (and not including) zero and one given
by~\eqref{eq:powerlimLR}. The intuition behind these results is that for a
normal design prior, there is always parameter uncertainty, even if the sample
size becomes arbitrarily large, while for point design priors, the parameter
uncertainty can be arbitrarily reduced by increasing the sample size. This
parallels similar results on bounds for hybrid Bayesian/frequentist power
\citep{Spiegelhalter2004, Micheloud2020, Grieve2022}.

\begin{figure}[!tb]
<< "plot-power", fig.height = 4.5 >>=
## BF parameters
k <- 1/10
null <- 0
sd <- sqrt(2) # unit SD for SMD effect size
pm <- dpm <- 0.3 # large SMD
psd1 <- dpsd1 <- 0 # point prior
psd2 <- dpsd2 <- 0.2 # normal prior

## plot power curves
par(mfrow = c(1, 2), mar = c(5.1, 4.2, 2, 1))
nseq <- exp(seq(log(10), log(10^5), length.out = 500))
yticks <- seq(0, 100, 20)
xticks <- c(1, 10, 10^2, 10^3, 10^4, 10^5)
lwd <- 1.5
xlabs <- as.expression(c(bquote(1), bquote(10),
                         sapply(seq(2, 5), FUN = function(x) bquote(10^.(x)))))
cols <- adjustcolor(col = c(2, 4), alpha = 0.8)
## point prior under the alternative
plot(nseq, pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd1,
                 dpm = dpm, dpsd = dpsd1)*100,
     xlab = bquote("Sample size per group" ~ italic(n)),
     ylab = bquote({"Pr(BF"["01"] <= 1/.(1/k)} ~ "|" ~ tau == 0 *")"),
     type = "l", xaxt = "n", yaxt = "n", ylim = c(0, 100), col = cols[1],
     lwd = lwd, log = "x", main = "Point analysis prior",
     panel.first = graphics::grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
axis(side = 1, at = xticks, labels = xlabs)
axis(side = 2, at = yticks, labels = paste0(yticks, "%"), las = 1)
lines(nseq,
      pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd1,
            dpm = dpm, dpsd = dpsd2)*100,
      lwd = lwd, col = cols[2])
zlim <- (null - pm)/(2*dpsd2)
plim <- 1 - pnorm(q = zlim)
abline(h = c(100, plim*100), lty = 2, col = adjustcolor(col = 1, alpha = 0.6))
legend("bottomright", bg = "white", title = "Design prior",
       legend = c(bquote("N(" * {mu[italic("d")] == .(pm)} * ","
                         ~ tau[italic("d")] == .(psd1) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(pm)} * ","
                         ~ tau[italic("d")] == .(psd2) * ")")),
       lwd = lwd, lty = 1, col = cols, cex = 0.7)

## normal prior under the alternative
plot(nseq, pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd2,
                 dpm = dpm, dpsd = dpsd1)*100,
     xlab = bquote("Sample size per group" ~ italic(n)),
     ylab = bquote({"Pr(BF"["01"] <= 1/.(1/k)} ~ "|" ~ tau == .(psd2) *")"),
     type = "l", xaxt = "n", yaxt = "n", ylim = c(0, 100), col = cols[1],
     lwd = lwd, log = "x", main = "Normal analysis prior",
     panel.first = graphics::grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
axis(side = 1, at = xticks, labels = xlabs)
axis(side = 2, at = yticks, labels = paste0(yticks, "%"), las = 1)
lines(nseq,
      pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd2,
            dpm = dpm, dpsd = dpsd2)*100, lwd = lwd,
      col = cols[2])
abline(h = 100, lty = 2, col = adjustcolor(col = 1, alpha = 0.6))
@
\caption{Examples of Bayes factor power curves computed with
  equation~\eqref{eq:prLR} (left) and~\eqref{eq:prBF} (right). Both Bayes
  factors contrast $H_{0} \colon \theta = \Sexpr{null}$ against
  $H_{1} \colon \theta \neq \Sexpr{null}$ for a standardized mean difference
  parameter $\theta$ with unit variance
  $\sigma^{2}_{\scriptscriptstyle \hat{\theta}} = 2$ with either a point
  analysis prior ($\tau = \Sexpr{psd1}$, left plot) or a normal analysis
  prior ($\tau = \Sexpr{psd2}$, right plot) both with $\mu = \Sexpr{pm}$. The
  power is computed under either a point (red curve) or normal design prior
  (blue curve), both at the same location as the analysis prior. The dashed
  lines depict the corresponding limiting power values.}
\label{fig:powerexamples}
\end{figure}

The left plot in Figure~\ref{fig:powerexamples} shows examples of two power
functions related to the Bayes factor for a standardized mean difference
parameter with point analysis prior. The power is computed under either a point
(red curve) or a normal design prior (blue curve). We see that increasing the
sample size $n$ increases the power in both cases. However, as known
from~\eqref{eq:powerlimLR}, the power under the normal design prior is bounded
by
$1 - \Phi\{(\theta_{0} + \mu - 2\mu_{d})/(2\tau_{d})\} = \Sexpr{round(plim*100,1)}\%$
while the power under the point design prior can be increased up to $100\%$.
Finally, the curves cross at 50\%, the intuition being that with the normal
design prior there is more uncertainty, and hence the power is always closer to
$50\%$.

For the Bayes factor with normal analysis prior ($\tau > 0$), the
cumulative distribution or power function is given by
\begin{align}
\label{eq:prBF}
    \Pr(\text{BF}_{01} \leq k \mid n, \mu_{d} , \tau_{d}, \tau > 0)
    %= \Pr(\chi^2_{1,\lambda} > X)
    = \Phi(-\sqrt{X} - M) + \Phi(-\sqrt{X} + M)
\end{align}
with 
\begin{align*}
    M = \left\{\mu_{d} - \theta_0 - \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2}(\theta_0 - \mu) \right\}\frac{1}{\sqrt{\tau^{2}_{d} + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n}}
\end{align*}
% non-centrality parameter
% \begin{align*}
%     \lambda = \left\{m - \theta_0 - \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2}(\theta_0 - \mu)\right\}^2 \frac{1}{v}
% \end{align*}
and
\begin{align*}
    X = \left\{\log\left(1 + \frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}\right) + \frac{(\theta_0 - \mu)^2}{\tau^2} - \log k^2\right\} \left(1 + \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2} \right) \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^{2}_{d} + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}},
\end{align*}
see Appendix~\ref{app:distributions} for details. Unlike the power function
based on the Bayes factor with point analysis prior~\eqref{eq:prLR}, the power
function based on the Bayes factor with normal analysis prior~\eqref{eq:prBF} can
be increased arbitrarily close to one by increasing the sample size $n$ (see
Appendix~\ref{app:asymptotics}). That is, we have that
\begin{align}
  \lim_{n\to \infty} \Pr(\text{BF}_{01} \leq k \mid n, \mu_{d} , \tau_{d}, \tau > 0) = 1
  \label{eq:plimBF}
\end{align}
regardless of whether the design prior is a point prior ($\tau_{d} = 0$) or
a normal prior ($\tau_{d} > 0$), provided that the design prior is not equal
to the point null hypothesis itself. This is expected because Bayes factors
contrasting point nulls against composite alternatives are `consistent' in the
sense that as the sample size increases, the probability of the Bayes factor
favoring the hypothesis under which the data were generated tends to one
\citep{Dawid2011,Bayarri2012,Ly2021}.

The right plot in Figure~\ref{fig:powerexamples} shows example power curves for
the Bayes factor related to a standardized mean difference parameter with normal
analysis prior, and computed under either point (red curve) or normal design
prior (blue curve). We see that in both cases an increase in sample size also
increases the power. As expected from~\eqref{eq:plimBF}, the power can increase
to $100\%$ in both cases, although it approaches the limit much slower under the
normal than under the point design prior because there is more uncertainty.
Finally, as with the point analysis prior Bayes factor, the curves cross at
50\%.


\section{Sample size determination}
\label{sec:ssd}
Both power functions~\eqref{eq:prLR} and~\eqref{eq:prBF} are straightforward to
implement and can be used to obtain power curves as a function of the sample
size, or of other parameters. We provide R implementations of both in our
package \texttt{bfpwr} (see Appendix~\ref{app:pkg} for an illustration).
Iterative root-finding can then be applied to determine the sample size such
that compelling evidence is obtained with a desired target power under a
specified design prior \citep[as pioneered by][]{Weiss1997}. It is worth noting
that one can also compute a power curve \emph{in favor of the null} hypothesis.
That is, one can look at one minus the power functions~\eqref{eq:prLR}
and~\eqref{eq:prBF} along with a Bayes factor threshold $k > 1$ and fixing the
design prior to the null hypothesis ($\mu_{d} = \theta_{0}$, $\tau_{d} = 0$). In
this way, sample sizes can be determined that guarantee a desired probability of
compelling evidence for the null. % This approach is also implemented in our R
% package.

We will now investigate situations where the sample size can be obtained in
closed-form. As for the distribution of the Bayes factor in the previous
section, there is again a distinction between sample size determination for
Bayes factors with point analysis priors ($\tau = 0$) and normal analysis priors
($\tau > 0$), we start again with the former.

\subsection{Bayes factor with point analysis prior}
Assuming that the alternative $\mu$ is larger than the null $\theta_{0}$ and
setting the power function~\eqref{eq:prLR} equal to a target power $1 - \beta$,
we obtain a quadratic equation in the sample size $n$.
% \begin{align*}
%   n^{2} \underbrace{\left\{\left(\frac{\theta_{0} + \mu}{2} - \mu_{d}\right)^{2} - z^{2}_{1 - \beta} \tau^{2}_{d}\right\}}_{=a} +
%   n \underbrace{\sigma^2_{\scriptscriptstyle \hat{\theta}}\left\{\frac{(\theta_{0} + \mu - 2 \mu_{d}) \log k}{\theta_{0} - \mu} - z^{2}_{1 - \beta}\right\}}_{=b} +
%   \underbrace{\left(\frac{\sigma^2_{\scriptscriptstyle \hat{\theta}} \log k}{\theta_{0} - \mu}\right)^{2}}_{=c} = 0.
% \end{align*}
Its solution can be expressed as
\begin{align}
\label{eq:nLR}
  n = \left[
  \left\{z_{1 - \beta} + \sqrt{z_{1 - \beta}^{2} - \frac{\Delta_{{\mu_{d}}}\log k^{2}}{\Delta_{\mu}} + \left(\frac{\tau_{d} \log k^{2}}{\Delta_{\mu}}\right)^{2}}\right\}^{2} - \left(\frac{\tau_{d} \log k^{2}}{\Delta_{\mu}}\right)^{2}\right]
  \times \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{
  \Delta_{\mu_{d}}^{2} - 4 z_{1 - \beta}^{2} \tau^{2}_{d}}
\end{align}
where $\Delta_{\mu_{d}} = 2\mu_{d} - \mu - \theta_{0}$ is the `generalized
effect size`, which reduces to the ordinary effect size
$\Delta_{\mu} = \mu - \theta_{0}$ when the design prior mean is set to the
parameter value under the alternative ($\mu_{d} = \mu$). From looking
at~\eqref{eq:nLR} one can recognize that a valid sample size can only exist if
the denominator in the right factor is positive, as sample sizes cannot be
negative. This condition is equivalent to the target power $1 - \beta$ being
lower than the limiting power~\eqref{eq:powerlimLR}. Of note, if for a given
design prior the limiting power~\eqref{eq:powerlimLR} is higher than 50\%,
replacing the first plus in~\eqref{eq:nLR} by a minus gives the sample size that
leads to a target power of $\beta$ instead of $1 - \beta$. It is also worth
noting that the sample size formula~\eqref{eq:nLR} will usually produce
non-integer values and hence needs to be rounded to the next larger integer in
order to be an evaluable sample size in practice (an actual number of
participants, animals, etc.).

<< "verify-equations", eval = FALSE >>=
## ## verify closed-form sample size formulas
## null <- 0.1
## pm <- 0.4
## psd <- 0
## dpm1 <- pm
## dpm2 <- 0.35
## dpsd1 <- 0
## dpsd2 <- 0.3
## sd <- sqrt(2)

## k <- 1/10
## power <- 0.63
## zb <- qnorm(p = power)

## ## formula (9)
## nbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = 0, dpm = pm,
##       dpsd = 0, analytical = c(FALSE, TRUE), integer = FALSE)
## sd^2*(zb + sqrt(zb^2 - log(k^2)))^2/(pm - null)^2

## ## formula (8)
## nbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = 0, dpm = dpm2,
##       dpsd = 0, analytical = c(FALSE, TRUE), integer = FALSE)
## sd^2*(zb + sqrt(zb^2 - log(k^2)*(null + pm - 2*dpm2)/(null - pm)))^2/(null + pm - 2*dpm2)^2

## ## formula (7)
## dpsd2 <- 0.1
## nbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = 0, dpm = dpm2,
##       dpsd = dpsd2, analytical = c(FALSE, TRUE), integer = FALSE)
## A <- sqrt(zb^2 - (2*dpm2 - null - pm)/(pm- null)*log(k^2) + (dpsd2*log(k^2)/(pm - null))^2)
## ((zb + A)^2 - (dpsd2*log(k^2)/(pm - null))^2)/(((2*dpm2- pm - null)^2 - 4*zb^2*dpsd2^2)/sd^2)
@

To better understand the sample size formula~\eqref{eq:nLR}, we will now
investigate it closer for two special cases. First, suppose that the design
prior is a point prior ($\tau_{d} = 0$) at $\mu_{d}$, not necessarily the
same as the alternative $\mu$. This leads to~\eqref{eq:nLR} reducing to
\begin{align}
  \label{eq:nLR2}
  n = \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}
  \left\{z_{1 - \beta} + \sqrt{z_{1 - \beta}^2 -  (\Delta_{\mu_{d}}/\Delta_{\mu}) \log k^2}\right\}^2}{\Delta_{\mu_{d}}^2}.
\end{align}
Assuming that the tested parameter is a mean difference with unit variance
$\sigma^2_{\scriptscriptstyle \hat{\theta}} = 2\sigma^{2}$ (see
Table~\ref{tab:outcomes}, second row), we can see that~\eqref{eq:nLR2}
represents a modification of the frequentist sample size
formula~\eqref{eq:freqsamplesize}: The effect size
$\Delta_{\mu} = \mu - \theta_0$ in the denominator of the frequentist sample
size is replaced by the generalized effect size $\Delta_{\mu_{d}}$ that takes
into account the mean of the design prior $\mu_{d}$, but reduces to the effect
size when the design prior mean equals parameter under the alternative
($\mu_{d} = \mu$). Moreover, the quantile $z_{1-\alpha/2}$ in the frequentist
sample size is replaced by
$\surd (z^2_{1-\beta} - (\Delta_{\mu_{d}}/\Delta_{\mu}) \log k^2)$, reflecting
the fact that we are interested in a Bayes factor hypothesis test with evidence
threshold $k$ instead of a frequentist test with level $\alpha$.

Second, assume that the design prior is also equal to the alternative
($\mu_{d} = \mu$), so that the formula~\eqref{eq:nLR2} further reduces to
\begin{align}
\label{eq:nLR3}
    n = \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}} \left\{z_{1 - \beta} + \sqrt{z_{1 - \beta}^2 - \log k^2}\right\}^2}{\Delta_{\mu}^2}.
\end{align}
The same formula~\eqref{eq:nLR3} was also found by \citet{Strug2007} for
`evidential' sample size calculations, but is unfortunately not well known. Not
surprisingly, the two formulas coincide, since Bayes factors and likelihood
ratios -- the measure of evidence used in evidential/likelihoodist statistics
\citep[see e.g.,][]{Edwards1971, Royall1997, Blume2002, Strug2018} -- are
equivalent when the Bayes factor involves only point hypotheses. Our more
general formulas~\eqref{eq:nLR} and~\eqref{eq:nLR2} thus enable `hybrid
Bayesian/likelihoodist' design that assumes a likelihoodist analysis but can
incorporate prior knowledge and uncertainty via Bayesian design prior, similar
to how Bayesian design priors can be used to incorporate parameter uncertainty
in the design of frequentist hypothesis tests \citep[see e.g.,][for an overview
of hybrid Bayesian/frequentist design approaches]{Grieve2022}.


\begin{table}[!htb]
\centering
\caption{Sample size per group $n$ to obtain a Bayes factor
  $\mathrm{BF}_{01} \leq k$ with at least a power of $1 - \beta$. The parameter
  of interest is a standardized mean difference and the analysis and design
  prior assume both an effect size of one ($\Delta_{\mu} = 1$) so that
  equation~\eqref{eq:nLR3} can be used to compute the sample size in
  closed-form.}
\label{tab:smdn}

  \rowcolors{1}{}{lightgray}
<< "nTable1", results = "asis" >>=
## produce a table with sample sizes based on closed-form sample size for LRs
kseq <- rev(c(1/1000, 1/300, 1/100, 1/30, 1/10, 1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3))
powseq <- seq(0.5, 0.95, 0.05)
smd <- 1
results <- sapply(X = kseq, FUN = function(k) {
    beta <- 1 - powseq
    zb <- qnorm(p = 1 - beta)
    (n <- (zb + sqrt(zb^2 - log(k^2)))^2/(smd^2/2))
})
colnames(results) <- formatBF(kseq)
rownames(results) <- paste0(powseq*100, "\\%")
xtab <- xtable(ceiling(results), digits = 0)
addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c(paste0("& \\multicolumn{", length(kseq), "}{c}{$k$} \\\\\n"),
                      paste(paste0("\\cmidrule{2-", length(kseq) + 1, "} \n"),
                            "$1 - \\beta$ &",
                            paste(formatBF(kseq), collapse = " & "), "\\\\"))
print(xtab, booktabs = TRUE, floating = FALSE,
      sanitize.rownames.function = function(x) x, add.to.row = addtorow,
      include.colnames = FALSE)
@
\end{table}

To illustrate formula~\eqref{eq:nLR3}, we now assume that $\hat{\theta}$ is a
standardized mean difference with unit variance
$\sigma^2_{\scriptscriptstyle \hat{\theta}} = 2$ so that $n$ can be interpreted
as the sample size per group (see the third row in Table~\ref{tab:outcomes}).
Table~\ref{tab:smdn} shows the sample size~\eqref{eq:nLR3} based on an assumed
effect size of one ($\Delta_{\mu} = 1$). We see, for instance, that a sample
size of
$n = \Sexpr{nbf01(k = 1/10, power = 0.8, sd = sqrt(2), pm = 1, psd = 0, integer = TRUE)}$
per group is required to achieve $1 - \beta = 80\%$ power for a Bayes factor
threshold $k = 1/10$. If the assumed effect size was smaller, the required
sample size would become larger. For example, for a half as large effect size,
the sample sizes from Table~\ref{tab:smdn} quadruple, e.g., requiring a sample
size of
$n = \Sexpr{nbf01(k = 1/10, power = 0.8, sd = sqrt(2), pm = 0.5, psd = 0, integer = TRUE)}$
per group to have $1 - \beta = 80\%$ power for a Bayes factor threshold of
$k = 1/10$.


\begin{figure}[!htb]
<< "plot-n", fig.height = 4.5 >>=
## BF parameters
k <- 1/10
null <- 0
sd <- sqrt(2) # unit SD for SMD effect size
pm <- dpm <- 1 # large SMD
psd1 <- dpsd1 <- 0 # point prior
psd2 <- dpsd2 <- 0.5 # normal prior

## plot sample sizes as a function of power
par(mfrow = c(1, 2), mar = c(5.1, 4.2, 2, 1))
powseq <- seq(0.25, 0.999999, length.out = 1000)
lwd <- 1.5
xticks <- seq(0, 100, 25)
yticks <- c(1, 10, 10^2, 10^3, 10^4, 10^5)
ylabs <- as.expression(c(bquote(1), bquote(10),
                         sapply(seq(2, 5), FUN = function(x) bquote(10^.(x)))))
cols <- adjustcolor(col = c(2, 4), alpha = 0.8)
## point prior under the alternative
plot(powseq*100,
     nbf01(k = k, power = powseq, sd = sd, null = null, pm = pm, psd = psd1,
           dpm = dpm, dpsd = dpsd1, analytical = TRUE, integer = TRUE),
     xlab = "Target power", ylab = bquote("Sample size per group" ~ italic(n)),
     type = "s", xaxt = "n", yaxt = "n", ylim = c(1, 10^4), col = cols[1],
     lwd = lwd, log = "y", main = "Point analysis prior",
     panel.first = graphics::grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
axis(side = 1, at = xticks, labels = paste0(xticks, "%"))
axis(side = 2, at = yticks, labels = ylabs, las = 1)
lines(powseq*100,
      nbf01(k = k, power = powseq, sd = sd, null = null, pm = pm, psd = psd1,
           dpm = dpm, dpsd = dpsd2, analytical = TRUE, integer = TRUE),
      col = cols[2], type = "s")
zlim <- (null - pm)/(2*dpsd2)
plim <- 1 - pnorm(q = zlim)
abline(v = c(100, plim*100), lty = 2, col = adjustcolor(col = 1, alpha = 0.6))
legend("bottomleft", bg = "white", title = "Design prior",
       inset = c(0.15, 0),
       legend = c(bquote("N(" * {mu[italic("d")] == .(pm)} * ", "
                         * tau[italic("d")] == .(psd1) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(pm)} * ", "
                         * tau[italic("d")] == .(psd2) * ")")),
       lwd = 1.5, lty = 1, col = cols, cex = 0.7)

## normal prior under the alternative
cols2 <- palette.colors(n = 2, palette = "Dark2", alpha = 0.9)
psdlocal1 <- 1
psdlocal2 <- sqrt(2)
nnormal1 <- ceiling(k^2*exp(-lambertWm1(x = -k^2*qnorm(p = powseq/2)^2))*2/psdlocal1^2)
nnormal2 <- ceiling(k^2*exp(-lambertWm1(x = -k^2*qnorm(p = powseq/2)^2))*2/psdlocal2^2)
plot(powseq*100, nnormal1, xlab = "Target power",
     ylab = bquote("Sample size per group" ~ italic(n)), type = "s", xaxt = "n",
     yaxt = "n", ylim = c(1, 10^4), col = cols2[1], lwd = lwd, log = "y",
     main = "Local normal analysis prior",
     panel.first = graphics::grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
lines(powseq*100, nnormal2, type = "s", col = cols2[2], lwd = lwd)
axis(side = 1, at = xticks, labels = paste0(xticks, "%"))
axis(side = 2, at = yticks, labels = ylabs, las = 1)
abline(v = 100, lty = 2, col = adjustcolor(col = 1, alpha = 0.6))
legend("bottom", bg = "white", title = "Analysis/design prior",
       legend = c(bquote("N(" * {mu[italic("d")] == .(null)} * ", "
                         * tau[italic("d")] == .(psdlocal1) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(null)} * ", "
                         * tau[italic("d")] == sqrt(.(psdlocal2^2)) * ")")),
       lwd = 1.5, lty = 1, col = cols2, cex = 0.7)
@
\caption{Examples of Bayes factor sample size calculations with
  equation~\eqref{eq:nLR} (left) and equation~\eqref{eq:nBF} (right). Both Bayes
  factors contrast $H_{0} \colon \theta = \Sexpr{null}$ against
  $H_{1} \colon \theta \neq \Sexpr{null}$ for a standardized mean difference
  parameter $\theta$ with unit variance
  $\sigma^{2}_{\scriptscriptstyle \hat{\theta}} = 2$ with either a point
  analysis prior ($\mu = \Sexpr{pm}$, $\tau = \Sexpr{psd1}$, left plot) or a
  local normal analysis prior ($\mu = \Sexpr{null}$, right plot), and at a
  threshold of $k = 1/\Sexpr{1/k}$. The dashed lines represent the upper bounds
  for the power that are achievable with a finite sample size.}
\label{fig:nexamples}
\end{figure}

The left plot in Figure~\ref{fig:nexamples} shows sample size calculations for a
Bayes factor at threshold $k = 1/\Sexpr{1/k}$ with the same point analysis and
design prior as in Table~\ref{tab:smdn} (red curve), but additionally
illustrates the sample size formula~\eqref{eq:nLR} that also incorporates
parameter uncertainty via a normal design prior (blue curve). We can see that
for a target power above 50\%, larger sample sizes are required under the normal
design prior than under the point design prior, while it is reversed for a
target power below 50\%. Furthermore, we see that as the target power approaches
its theoretical upper bound~\eqref{eq:powerlimLR}, the sample size goes to
infinity.


\subsection{Bayes factor with normal analysis prior}
Finding a sample size formula becomes more difficult when we move from point to
normal analysis priors. The technical reason is that when we set the power
function~\eqref{eq:prBF} equal to a target power and try to solve for the sample
size $n$, we have $n$ appearing both in and outside logarithms. This forms a
transcendental equation that cannot be solved in terms of elementary functions.
We were unable to find a closed-form solution in the general case. However, as
we will show now, solutions can, under certain conditions, be expressed in terms
of the Lambert W function \citep{Corless1996}. The Lambert W function is the
function $\mathrm{W}(\cdot)$ that satisfies
$\mathrm{W}(x)\exp\{\mathrm{W}(x)\}=x$, and it is therefore sometimes also
called `product logarithm'. It has many fundamental applications, such as the
solution of the Schrödinger equation in quantum-mechanics, and has also
previously appeared in the context of Bayes factor hypothesis testing
\citep{Pawel2022b, Wagenmakers2022, Held2021b, Pawel2023}.

Suppose now that the design and analysis prior are both centered around the null
value \mbox{($\mu_{d} = \mu = \theta_0$)}. Centering the prior around the null
value is commonly done in `default' Bayes factor tests \citep{Berger1987b}. It
encodes the assumption that some parameters are larger while others are smaller
than the null, the standard deviation of the distribution determining the
variability, yet the average parameter equals the null value. We then have that
$M=0$ and hence the power~\eqref{eq:prBF} reduces to
\begin{align}
  \label{eq:prBFcenter}
    \Pr\{\text{BF}_{01} \leq k \mid n, \tau_{d}, \mu_{d} = \mu = \theta_{0}\}
    = 2\Phi(-\sqrt{X}).
\end{align}
Further, assume that the variance of the design prior corresponds to the
variance of the analysis prior ($\tau_{d} = \tau$). We then have that
\begin{align*}
    X = \left\{\log\left(1 + \frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}\right) - \log k^2\right\} \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2}.
\end{align*}
Setting the power function~\eqref{eq:prBFcenter} equal to a target power of
$1 - \beta$ and assuming that
$\log\{1 + (n\tau^2)/\sigma^2_{\scriptscriptstyle \hat{\theta}}\} \approx \log\{(n\tau^2)/\sigma^2_{\scriptscriptstyle \hat{\theta}}\}$,
we obtain the following approximate sample size formula
\begin{align}
\label{eq:nBF}
  n = \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{\tau^2} \, \underbrace{k^2  \exp\left\{-  \mathrm{W}_{-1}(-k^2 \, z^2_{(1 - \beta)/2})\right\}}_{=n_{k,\beta}}
\end{align}
with $\mathrm{W}_{-1}(\cdot)$ the branch of the Lambert W function that
satisfies $\mathrm{W}(x) < -1$ for $y \in (-1/e, 0)$ \citep{Corless1996}, see
Appendix~\ref{app:lambertWderiv} for details.

We can see that the sample size~\eqref{eq:nBF} depends on the ratio of the unit
variance $\sigma^{2}_{\scriptscriptstyle \hat{\theta}}$ to the prior variance
$\tau^{2}$ multiplied by a `unit information sample size' $n_{k,\beta}$ which
depends only on the Bayes factor threshold $k$ and the target power $1 - \beta$.
% (albeit they are transformed with the Lambert W function).
The unit information sample size is the sample size that is obtained when a unit
information prior \citep{Kass1995b} is specified, which is a prior with variance
equal to the unit variance
($\tau^{2} = \sigma^{2}_{\scriptscriptstyle \hat{\theta}}$). As with the
frequentist sample size~\eqref{eq:freqsamplesize}, smaller unit variances
$\sigma^{2}_{\scriptscriptstyle \hat{\theta}}$ reduce the sample
size~\eqref{eq:nBF}. The prior variance $\tau^{2}$ determines how large
parameters are expected under the alternative hypothesis, and as such, larger
prior variances lead to a reduction of sample size similar to how larger effect
sizes lead to a reduction of sample size in the frequentist
formula~\eqref{eq:freqsamplesize}. Finally, the formula~\eqref{eq:nBF} allows us
to study the potential existence of a sample size that can achieve the target
power: Since the argument of the Lambert W function has to be at least $-1/e$
for it to be defined, we can infer that only combinations of Bayes factor
thresholds $k$ and power values $1 - \beta$ that satisfy
$-k^{2} z^{2}_{(1 - \beta)/2} \geq -1/e$ can actually be achievable with a finite
sample size. For example, it is impossible to find a sample size that guarantees
a power of $1 - \beta = 50\%$ for a threshold of $k = 1$ since then
$- 1 \times z_{0.25}^{2} = \Sexpr{round(-qnorm(0.25)^2, 2)} < -1/e = \Sexpr{-round(1/exp(1), 2)}$.


\begin{table}[!htb]
\centering
\caption{Required unit information sample size $n_{k,\beta}$ computed with
  equation~\eqref{eq:nBF} to obtain a Bayes factor $\mathrm{BF}_{01} \leq k$
  with at least a power of $1-\beta$ with a unit information analysis and design
  prior.}
\label{tab:nnormal}

  \rowcolors{1}{}{lightgray}
<< "nTable2", results = "asis" >>=
## produce a table with sample sizes computed with formula
kseq <- rev(c(1/1000, 1/300, 1/100, 1/30, 1/10, 1/9, 1/8, 1/7, 1/6, 1/5, 1/4, 1/3))
powseq <- seq(0.5, 0.95, 0.05)
results <- sapply(X = kseq, FUN = function(k) {
    beta <- 1 - powseq
    k^2*exp(-lambertWm1(x = -k^2*qnorm(p = (1 - beta)/2)^2))
})
colnames(results) <- formatBF(kseq)
rownames(results) <- paste0(powseq*100, "\\%")
xtab <- xtable(ceiling(results), digits = 0)
addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c(paste0("& \\multicolumn{", length(kseq), "}{c}{$k$} \\\\\n"),
                      paste(paste0("\\cmidrule{2-", length(kseq) + 1, "} \n"),
                            "$1 - \\beta$ &",
                            paste(formatBF(kseq), collapse = " & "), "\\\\"))
print(xtab, booktabs = TRUE, floating = FALSE,
      sanitize.rownames.function = function(x) x, add.to.row = addtorow,
      include.colnames = FALSE)
@
\end{table}

Table~\ref{tab:nnormal} shows unit information sample sizes $n_{k,\beta}$ for a
range of powers $1 - \beta$ and Bayes factor thresholds $k$. Compared to the
sample sizes from Table~\ref{tab:smdn} the sample sizes are quite a bit larger.
This is because the design and analysis priors underlying each of these
calculations encode vastly different assumptions: The local normal analysis
prior from Table~\ref{tab:nnormal} represents a parameter distribution that is
centered around the null value while the point analysis prior from
Table~\ref{tab:smdn} represents a mean difference of one standard deviation away
from the null. The former with unit information variance represents a more
pessimistic assumption about the parameter than the latter. To incorporate more
optimistic beliefs into the calculations we may increase the standard deviation
$\tau$ of the distribution as this encodes the assumption of potentially larger
parameters. For example, doubling $\tau$ leads to a four-fold decrease of the
sample size~\eqref{eq:nBF}. This is also illustrated in the right plot of
Figure~\ref{fig:nexamples} where the prior with doubled variance (orange curve)
leads to a two-fold decrease in sample size over the prior with variance of one
(green curve).

The formula~\eqref{eq:nBF} is, to our knowledge, the first closed-form sample
size formula for Bayes factor analysis with normal analysis priors. While
interesting from a theoretical point of view, its practical use is perhaps more
limited than the sample size formula for Bayes factors with point analysis
priors~\eqref{eq:nLR}. This is because it makes the restrictive assumption that
the design prior and the analysis prior are both centered around the null
($\mu_{d} = \mu = \theta_{0}$). This seems unrealistic in practice, since
researchers designing a study usually have good reasons to expect parameters to
be different from the null and would like to account for this in the sample size
calculation. However, given our limited mathematical abilities, we have not been
able to derive a sample size formula for this more general setting due to the
transcendental nature of the power equation. Fortunately, the sample size can
still be easily calculated numerically with our R package which is quicker and
more reliable than computing it with a simulation approach.


\section{Application}
\label{sec:application}
We will now illustrate Bayes factor sample size and power calculations using
examples from medicine and psychology.

\subsection{Randomized controlled clinical trial on treatment of influenza}
\citet{MIST1998} conducted a randomized controlled clinical trial to evaluate
the efficacy of the drug `zanamivir' in the treatment of influenza A and B. The
primary endpoint of the trial was the time in days to relief of clinically
important symptoms of influenza. This outcome was treated as continuous by the
investigators, and the parameter of interest was the mean difference in time to
relief between the treatment and placebo groups $\theta$. We note that it might
be preferable to treat this as a survival outcome and use a (log) hazard ratio
parameter to quantify the effect size, but to stay close to the original
analysis we will use the continuous outcome approach. The null hypothesis was
defined as no difference in efficacy of the treatment
($H_{0} \colon \theta = 0$), whereas the alternative hypothesis was defined as a
clinically relevant difference of one day ($H_{1} \colon \theta = 1$). For
sample size calculations, the investigators used a standard deviation of
$\sigma = 2.75$ estimated from a previous study.

While this study was analyzed using frequentist methodology, we will now examine
what the power and sample size calculations might look like if the planned
analysis were performed using Bayes factors. For doing so, we assume a point
analysis prior for the Bayes factor that equals the alternative hypothesis
specified by the trial investigators ($\mu = 1$ and $\tau = 0$), so that the
Bayes factor corresponds with a likelihood ratio. Hence, we can use the power
function~\eqref{eq:prLR} and sample size formula~\eqref{eq:nLR} to compute power
and sample size under point and normal design priors, which we illustrate in the
following.

\begin{figure}[!tb]
<< fig.height = 6 >>=
## A randomized trial to assess the effectiveness of zanamivir, a new treatment for
## influenza, compared a group randomly allocated to the new treatment with a group
## randomly allocated to a sham (or placebo) treatment. When planning the trial the
## investigators decided that the primary variable would be the number of days to
## the alleviation of symptoms (with alleviation and symptoms defined precisely
## elsewhere in the plan of the study).

## A previous study suggested that a sensible value for sd was 2.75 d and the
## minimal clinically relevant difference that the trial should have good power
## to detect was taken to be 1 d.

## BF parameter
null <- 0
sd <- sqrt(2)*2.75 # unit sd for an MD effect size so that n is the group size
pm <- 1 # the effect on MD scale
psd <- 0 # point analysis prior
k <- 1/10

## design parameters
power <- 0.9
dpm <- pm
dpsd1 <- 0
dpsd2 <- 1/4

## compute required sample size to achieve 80% power for LR
nnum <- nbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = psd,
              dpm = dpm, dpsd = dpsd1)
zb <- qnorm(p = power)
nanalyt <- ceiling((zb + sqrt(zb^2 - log(k^2)*(pm + null - 2*dpm)/(null - pm)))^2/
                   (pm + null - 2*dpm)^2*sd^2)
a <- ((null + pm)/2 - dpm)^2 - zb^2*dpsd2^2
b <- sd^2*((null + pm - 2*dpm)*log(k)/(null - pm) - zb^2)
c <- (sd^2*log(k)/(null - pm))^2
nanalyt2 <- ceiling((-b + sqrt(b^2 - 4*a*c))/(2*a))


## ## sample size to achieve 80% power under the null
## nbf01(k = 1/k, power = power, sd = sd, null = null, pm = pm, psd = psd,
##       dpm = null, dpsd = 0, lower.tail = FALSE, analytical = FALSE)

## plot power curves
par(mfrow = c(2, 1), mar = c(2.5, 5, 2.5, 2.5))
cols <- rev(palette.colors(n = 4, alpha = 0.95)[2:4])
transpblack <- adjustcolor(col = 1, alpha = 0.2)
nseq <- seq(from = 5, to = 550, by = 1)
pow <- pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
             dpm = dpm, dpsd = dpsd1)
pow2 <- pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
              dpm = dpm, dpsd = dpsd2)
powNull <- pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
                 dpm = null, dpsd = 0)
plot(nseq, pow*100, xlab = "",
     ylab = bquote("Pr(BF"["01"] < 1/.(1/k) * " )"), type = "l",
     ylim = c(0, 100), lwd = 1.5, yaxt = "n", col = cols[1],
     panel.first = graphics::grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
lines(nseq, pow2*100, type = "l", col = cols[2], lwd = 1.5)
lines(nseq, powNull*100, type = "l", col = cols[3], lwd = 1.5)
axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
axis(side = 4, at = power*100, labels = paste0(power*100, "%"), las = 1,
     col = transpblack, cex.axis = 0.8)
axis(side = 3, at = c(nanalyt, nanalyt2), col = transpblack, cex.axis = 0.8)
abline(h = power*100, col = transpblack)
abline(v = c(nanalyt, nanalyt2), col = transpblack)
legend("right", title = "Design prior",
       legend = c(bquote("N(" * {mu[italic("d")] == .(dpm)} * ", "
                         * tau[italic("d")] == .(dpsd1) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(dpm)} * ", "
                         * tau[italic("d")] == .(dpsd2) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(null)} * ", "
                         * tau[italic("d")] == 0 * ")")),
       lty = 1, lwd = 1.5, col = cols, bg = "white", cex = 0.7)
par(mar = c(4, 5, 1, 2.5))
powH0 <- pbf01(k = 1/k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
               dpm = dpm, dpsd = dpsd1, lower.tail = FALSE)
pow2H0 <- pbf01(k = 1/k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
                dpm = dpm, dpsd = dpsd2, lower.tail = FALSE)
powNullH0 <- pbf01(k = 1/k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
                   dpm = null, dpsd = 0, lower.tail = FALSE)
plot(nseq, powH0*100, xlab = bquote("Sample size per group" ~ italic(n)),
     ylab = bquote("Pr(BF"["01"] > .(1/k) * " )"), type = "l",
     ylim = c(0, 100), lwd = 1.5, yaxt = "n", col = cols[1],
     panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
lines(nseq, pow2H0*100, type = "l", col = cols[2], lwd = 1.5)
lines(nseq, powNullH0*100, type = "l", col = cols[3], lwd = 1.5)
axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
abline(v = nanalyt, col = transpblack)
abline(h = power*100, col = transpblack)
axis(side = 4, at = power*100, labels = paste0(power*100, "%"), las = 1,
     col = transpblack, cex.axis = 0.8)
@
\caption{Power and sample size calculations for MIST trial \citep{MIST1998}. The
  Bayes factor assumed for the analysis contrasts
  $H_{0} \colon \theta = \Sexpr{null}$ to $H_{1} \colon \theta = \Sexpr{pm}$.
  The power is computed under either a point prior at the assumed effect under
  the alternative (green), a normal prior that incorporates additional parameter
  uncertainty (blue), or under the null hypothesis (orange).}
\label{fig:MIST}
\end{figure}

Figure~\ref{fig:MIST} shows power curves based on the Bayes factor providing
strong evidence in favor of the alternative ($\mathrm{BF}_{01} < 1/\Sexpr{1/k}$)
in the top plot, and based on the Bayes factor providing strong evidence in
favor of the null ($\mathrm{BF}_{01} > \Sexpr{1/k}$) in the bottom plot. The
colors indicate under which design prior the power was computed.

Focusing on the top plot, we can see from the green curve that a sample size of
at least $n = \Sexpr{nanalyt}$ per group are required to ensure a target power
of $1 - \beta = \Sexpr{round(power*100,2)}\%$ assuming that the same point prior
is used in the design as for the analysis (i.e., a point prior at
$\mu = \Sexpr{pm}$). This number increases to $n = \Sexpr{nanalyt2}$ when we
move to a design prior that incorporates parameter uncertainty (blue curve),
i.e., a prior that is still centered around $\mu = \Sexpr{pm}$ but with a
standard deviation of $\tau_{d} = \Sexpr{dpsd2}$. Finally, if we look at the
orange power curve computed assuming that the null hypothesis is true
($\theta = \Sexpr{null}$), we can see that the probability of misleading
evidence for the alternative when the null hypothesis is actually true is very
low and appears to be adequately controlled by conventional standards (i.e.,
below 5\%) for each of the two sample sizes.

Focusing now on the bottom plot, we can see that the sample size
$n = \Sexpr{nanalyt}$ also ensures a power of
$1 - \beta = \Sexpr{round(power*100,2)}\%$ for finding evidence for the null
hypothesis. This is due to the symmetric nature of the point versus point
hypothesis Bayes factor considered in this example, as swapping the null
$\theta_{0}$ and alternative $\mu$ in formula~\eqref{eq:nLR3} does not change
the resulting sample size. Finally, looking at the green and blue curves we can
see that the probability of misleading evidence in favor of the null when the
data are generated from the non-null design priors seems to be reasonably well
controlled (below 5\%) across the whole range of sample sizes considered.


\subsection{Comparison to Monte Carlo simulation methods}
\label{sec:schoenbrodtexample}
\citet{Schoenbrodt2017} proposed a Monte Carlo simulation approach for power and
sample size calculations for Bayes factor analyses, and they provide the R
package \texttt{BFDA} \citep{Schoenbrodt2019} for this purpose. The idea is to
simulate data sets under an assumed design prior and sample size, and then
analyze each data set with a specified Bayes factor. This results in a
distribution of Bayes factors from which the power can be calculated. The
simulation is then repeated for other sample sizes until the desired power is
achieved. This approach can be used in quite general settings, but can be
computationally intensive and comes with Monte Carlo error.
% For example, the BFDA package is widely used in Psychology where researchers
% often perform Bayes factor hypothesis testing with the default
% `Jeffreys-Zellner-Siow' prior assigned to effect sizes under the alternative
% \citep{Rouder2009}. This type of prior necessitates the use of simulation for
% power and sample size calculcations as the resulting Bayes factor is no longer
% available in closed-form.


\begin{figure}[!tb]
<< fig.height = 6 >>=
## "1) In the example given below, we used two populations with normal
## distributions and a fixed standardized mean difference of delta =0.5 3) In
## the example given below, we analyzed simulated data with a Cauchy prior"
## (scale parameter = 1/sqrt(2))"


## ## compare Normal to Cauchy prior
## xseq <- seq(-3, 3, 0.01)
## matplot(xseq, cbind(dnorm(xseq, mean = 0, sd = 1/sqrt(2)),
##                     dcauchy(xseq, location = 0, scale = 1/sqrt(2))),
##         type = "l", lty = c(1, 2), col = 1, xlab = "x", ylab = "density")
## legend("topright", legend = c("Normal(0, variance = 1/2)", "Cauchy(0, scale = 1/sqrt(2))"),
##        lty = c(1, 2))

## BF parameter
null <- 0
sd <- sqrt(2) # unit sd for an SMD effect size so that n is the group size
pm <- 0
psd <- 1/sqrt(2)
k <- 1/6

## design parameters
power <- 0.95
dpm <- 0.5
dpsd <- 0
dpsd2 <- 0.1

## compute required sample size to achieve target power
n <- nbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = psd,
           dpm = dpm, dpsd = dpsd)
n2 <- nbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = psd,
            dpm = dpm, dpsd = dpsd2)
nH0 <- nbf01(k = 1/k, power = power, sd = sd, null = null, pm = pm, psd = psd,
             dpm = null, dpsd = 0, lower.tail = FALSE)

## ## under the null
## nbf01(k = 1/k, power = power, sd = sd, null = null, pm = pm, psd = psd, dpm = null,
##       dpsd = 0, lower.tail = FALSE)

## compute power curve
nseq <- seq(from = 2, to = 800, by = 1)
pow <- pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
             dpm = dpm, dpsd = dpsd)
powH0 <- pbf01(k = 1/k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
               dpm = dpm, dpsd = dpsd, lower.tail = FALSE)
powNull <- pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
                 dpm = null, dpsd = 0)
powNullH0 <- pbf01(k = 1/k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
                   dpm = null, dpsd = 0, lower.tail = FALSE)
pow2 <- pbf01(k = k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
              dpm = dpm, dpsd = dpsd2)
pow2H0 <- pbf01(k = 1/k, n = nseq, sd = sd, null = null, pm = pm, psd = psd,
                dpm = dpm, dpsd = dpsd2, lower.tail = FALSE)

## compute power curve with BFDA simulation package
nMC <- 1000
## library(BFDA)
## BFDAsim <- BFDA.sim(expected.ES = dpm, type = "t.between",
##                     alternative = "two.sided",
##                     prior = list("normal", list(prior.mean = pm, prior.variance = psd^2)),
##                     design = "sequential", stepsize = 5, n.min = min(nseq),
##                     n.max = max(nseq), B = nMC, seed = 4242, cores = 10)
## ##> Duration: Time difference of 11.64552 mins
## set.seed(43)
## BFDAsim2 <- BFDA.sim(expected.ES = rnorm(n = nMC, mean = dpm, sd = dpsd2),
##                      type = "t.between", alternative = "two.sided",
##                      prior = list("normal", list(prior.mean = pm, prior.variance = psd^2)),
##                      design = "sequential", stepsize = 5, n.min = min(nseq),
##                      n.max = max(nseq), B = nMC, seed = 42462, cores = 10)
## ##> Duration:  Time difference of 11.88571 mins
## BFDAsimNull <- BFDA.sim(expected.ES = null, type = "t.between",
##                         alternative = "two.sided",
##                         prior = list("normal", list(prior.mean = pm, prior.variance = psd^2)),
##                         design = "sequential", stepsize = 5, n.min = min(nseq),
##                         n.max = max(nseq), B = nMC, seed = 4245, cores = 10)
## ##> Duration: Time difference of 8.955649 mins
## save(BFDAsim, BFDAsim2, BFDAsimNull, file = "./BFDAsim.RData")
load(file = "./BFDAsim.RData")
nseqBFDA <- unique(BFDAsim$sim$n)
powBFDA <- lapply(X= list(BFDAsim, BFDAsim2, BFDAsimNull), FUN = function(df) {
    t(sapply(X = nseqBFDA, FUN = function(ni) {
        subdf <- subset(df$sim, n == ni)
        c(mean(subdf$logBF > log(1/k)),
          mean(subdf$logBF < log(k)))
    }))
})

## plot power curves
plotSimCurve <- function(nseq, powe, nMC, col) {
    lines(nseq, powe*100, type = "l", col = col, lwd = 1, lty = 2)
    mcse <- sqrt(powe*(1 - powe)/nMC)
    polygon(x = c(nseq, rev(nseq)), y = c(powe + mcse, rev(powe - mcse))*100,
            border = FALSE, col = adjustcolor(col = col, alpha.f = 0.3),
            lty = 2)
}
par(mfrow = c(2, 1), mar = c(2.5, 5, 2.5, 2.5))
transpblack <- adjustcolor(col = 1, alpha = 0.2)
plot(nseq, pow*100, xlab = "",
     ylab = bquote("Pr(BF"["01"] < 1/.(1/k) * " )"), type = "l",
     ylim = c(0, 100), lwd = 1.5, yaxt = "n", col = cols[1],
     panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
lines(nseq, pow2*100, type = "l", col = cols[2], lwd = 1.5)
lines(nseq, powNull*100, type = "l", col = cols[3], lwd = 1.5)
for (i in seq(1, length(powBFDA))) {
    plotSimCurve(nseq = nseqBFDA, pow = powBFDA[[i]][,1], nMC = nMC,
                 col = cols[i])
}
axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
axis(side = 4, at = power*100, labels = paste0(power*100, "%"), las = 1,
     col = transpblack, cex.axis = 0.8)
axis(side = 3, at = c(n, n2), col = transpblack, cex.axis = 0.8)
abline(h = power*100, col = transpblack)
abline(v = c(n, n2), col = transpblack)
legend("topright", inset = c(0, 1/6), title = "Design prior",
       legend = c(bquote("N(" * {mu[italic("d")] == .(dpm)} * ", "
                         * tau[italic("d")] == .(dpsd) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(dpm)} * ", "
                         * tau[italic("d")] == .(dpsd2) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(null)} * ", "
                         * tau[italic("d")] == 0 * ")")),
       lty = 1, lwd = 1.5, col = cols, bg = "white", cex = 0.7)
legend("bottomright", inset = c(0, 1/6), title = "Computational method",
       legend = c("Closed-form", "Simulation"), lty = c(1, 2), lwd = c(1.5, 1),
       col = 1, bg = "white", cex = 0.7)
par(mar = c(4, 5, 1, 2.5))
plot(nseq, powH0*100, xlab = bquote("Sample size per group" ~ italic(n)),
     ylab = bquote("Pr(BF"["01"] > .(1/k) * " )"), type = "l",
     ylim = c(0, 100), lwd = 1.5, yaxt = "n", col = cols[1],
     panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
lines(nseq, pow2H0*100, type = "l", col = cols[2], lwd = 1.5)
lines(nseq, powNullH0*100, type = "l", col = cols[3], lwd = 1.5)
for (i in seq(1, length(powBFDA))) {
    plotSimCurve(nseq = nseqBFDA, pow = powBFDA[[i]][,2], nMC = nMC,
                 col = cols[i])
}
axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
@
\caption{Power and sample size calculation for example adapted from
  \citet[p.~133]{Schoenbrodt2017}. The Bayes factor assumed for the analysis
  contrasts $H_{0} \colon \theta = \Sexpr{null}$ to
  $H_{1} \colon \theta \neq \Sexpr{null}$ with
  \mbox{$\theta \mid H_{1} \sim \mathrm{N}(\mu = \Sexpr{pm}, \tau^{2} = 1/\Sexpr{1/psd^2})$}
  prior assigned to the standardized mean difference $\theta$ under the
  alternative. The power is computed under either a point prior at a medium
  effect size (green), a normal prior that incorporates additional parameter
  uncertainty (blue), or under the null hypothesis (orange). For comparison,
  \Sexpr{nMC} Monte Carlo simulations are performed with the \texttt{BFDA}
  package \citep{Schoenbrodt2019} to obtain a simulation-based power curve
  approximation (dashed line with one Monte Carlo standard error band).}
\label{fig:comparisonBFDA}
\end{figure}

We will now look at an adaptation of an example examined in
\citet[p.~133]{Schoenbrodt2017}. Suppose we want to test the null hypothesis
that a standardized mean difference $\theta$ is zero
($H_{0} \colon \theta = \Sexpr{null}$) versus the alternative hypothesis that it
is different from zero ($H_{1} \colon \theta \neq \Sexpr{null}$). We assume a
$\theta \mid H_{1} \sim \mathrm{N}(\Sexpr{pm}, 1/\Sexpr{1/psd^2})$ analysis
prior for the standardized mean difference under the alternative, similar to the
Cauchy prior with scale $1/\sqrt{\Sexpr{1/psd^2}}$ that was assumed by
\citet{Schoenbrodt2017}. As they did, we also investigate two design priors:
either a point prior at $\mu_{d} = \Sexpr{dpm}$ , which is a convention for a
`medium` standardized mean difference in psychology \citep{Cohen1992}, or a
normal prior at $\mu_{d} = \Sexpr{dpm}$ with standard deviation
$\tau_{d} = \Sexpr{dpsd2}$ to incorporate parameter uncertainty.
Figure~\ref{fig:comparisonBFDA} shows the resulting power curves computed from
equation~\eqref{eq:prBF}, along with the \texttt{BFDA} Monte Carlo simulation
approximations (with Monte Carlo standard error bands) for comparison. The
closed-form power curves were computed instantly while each simulated power
curve took about 10 minutes to compute when parallelized across 10 cores on a
modern laptop (Lenovo X1 Gen 8 with Intel i7-1355U CPU and 32GB RAM).

We see that closed-form and simulation curves closely align in all cases,
although the former shows Monte Carlo error. Looking at the green curves in the
top plot, we see that a sample size of $n = \Sexpr{n}$ per group is sufficient
to achieve a target power of $\Sexpr{100*power}\%$ with a Bayes factor threshold
of $k = 1/\Sexpr{1/k}$ under the point design prior. This sample size is
slightly larger than the $n = 146$ that \citet{Schoenbrodt2017} obtained in
their calculations, which instead assumed a Cauchy analysis prior. As in the
previous example, incorporating parameter uncertainty via a normal design prior
increases the required sample size, in this case to $n = \Sexpr{n2}$. Looking at
the orange curve in the bottom plot, we see that these sample sizes only have
modest power of around $20\%$ and $50\%$, respectively, for obtaining evidence
in favor of the true null hypothesis (at a threshold of $k = 6$). To obtain a
power of $\Sexpr{100*power}\%$, a sample size of $n = \Sexpr{nH0}$ per group
would be required (not shown in Figure~\ref{fig:comparisonBFDA}). This
illustrates the well-known fact that evidence accumulates slower for the null
than the alternative when the Bayes factor involves testing a point null against
a composite alternative with normal analysis prior \citep{Johnson2010}. Finally,
looking at the orange curve in the top plot and the green/blue curves in the
bottom plot, we see that the probability of misleading evidence in favor of the
incorrect hypothesis appears to be adequately controlled, as these curves are
virtually zero over the entire range of sample sizes.

\section{Extensions}
\label{sec:extensions}
The types of Bayes factors that we considered so far are limited to data in the
form of asymptotically normally distributed parameter estimates, and normal or
point priors in the analysis. Researchers may also want to use different data
models or prior distributions in the analysis. In the following, we outline two
extensions that modify the Bayes factor used for the analysis, while still
retaining the normal likelihood and point/normal design prior used for the
design.

\subsection{Informed Bayesian \textit{t}-test}

\citet{Gronau2020} proposed a Bayes factor for testing a standardized mean
difference parameter based on normally distributed data with unknown variance --
the same situation where a classical $t$-test would be used. The Bayes factor is
given by
\begin{align}
  \mathrm{BF}_{01} = \frac{\mathrm{T}_{\nu}(t \mid 0, 1)}{\int_{-\infty}^{+\infty}
  \mathrm{NCT}_{\nu}(t \mid \theta \sqrt{n}) \, \mathrm{T}_{\kappa}(\theta \mid \mu, \tau)_{[a,b]}
  \, \mathrm{d}\theta}
  \label{eq:tBF}
\end{align}
with $t$ the $t$-test statistic, $n$ the effective sample size (the actual
number of observations/pairs for one-sample/paired $t$-tests, or
$n = 1/(1/n_{1} + 1/n_{2})$ for two-sample $t$-tests),
$\mathrm{T}_{\nu}(\cdot \mid \mu, \tau)$ the location-scale $t$ density with
degrees of freedom $\nu$, location $\mu$, and scale $\tau$, and
$\mathrm{NCT}_{\nu}(\cdot \mid \lambda)$ the non-central $t$ density with
degrees of freedom $\nu$ and non-centrality parameter $\lambda$ \citep[chapters
28 and 31]{Johnson1995}. The subscript $[a,b]$ denotes truncation of a
distribution to the interval from $a$ to $b$, i.e.,
$f(x)_{[a,b]} = \{f(x) 1_{[a,b]}(x)\}/\{F(a) - F(b)\}$. For example, for a
one-sided test in positive direction, we have $a = 0$ and $b=+\infty$, while for
a two-sided test we have $a = -\infty$ and $b=+\infty$. When the prior under the
alternative is set to a (scaled) Cauchy distribution ($\kappa = 1$, $\mu = 0$,
$a = -\infty$, $b=+\infty$), the Bayes factor reduces to the
`Jeffreys-Zellner-Siow' (JZS) Bayes factor \citep{Jeffreys1961, Zellner1980},
which is often used as a `default' Bayes factor in the social sciences
\citep{Rouder2009}. Setting other values for these parameters allows data
analysts to incorporate directionality, such as a one-sided JZS Bayes factor
\citep{Wetzels2009}, or prior knowledge about the standardized mean difference,
potentially improving the efficiency of the test \citep{Stefan2019}. The Bayes
factor~\eqref{eq:tBF} is also implemented in our package in the function
\texttt{tbf01}.

<< "extensions-t-example", fig.height = 4.5 >>=
null <- 0
plocation <- 0
pscale <- 1/sqrt(2)
pdf <- 1
dpm <- 0.5
dpsd1 <- 0
dpsd2 <- 0.1
power <- 0.95
k <- 1/6
alternative <- "greater"
type <- "two.sample"
nex <- ntbf01(k = k, power = power, null = null, plocation = plocation,
              pscale = pscale, pdf = pdf, alternative = alternative,
              type = type, dpm = dpm, dpsd = c(dpsd1, dpsd2))


## library(microbenchmark)
## microbenchmark({
##     ntbf01(k = k, power = power, null = null, plocation = plocation,
##               pscale = pscale, pdf = pdf, alternative = alternative,
##               type = type, dpm = dpm, dpsd = dpsd1)
## })
## #> Unit: milliseconds
## #>       min       lq     mean   median       uq      max neval
## #>  94.27834 96.52802 99.69758 97.41885 98.79241 177.8769   100

## ## plot power curves
## nseq <- seq(5, 300, 1)
## pow <- ptbf01(k = k, n = nseq, null = null, plocation = plocation,
##               pscale = pscale, pdf = pdf, alternative = alternative,
##               type = type, dpm = dpm, dpsd = dpsd1)
## pow2 <- ptbf01(k = k, n = nseq, null = null, plocation = plocation,
##                pscale = pscale, pdf = pdf, alternative = alternative,
##                type = type, dpm = dpm, dpsd = dpsd2)
## powNull <- ptbf01(k = k, n = nseq, null = null, plocation = plocation,
##                   pscale = pscale, pdf = pdf, alternative = alternative,
##                   type = type, dpm = null, dpsd = 0)
## par(mar = c(4, 5, 4, 2.5))
## matplot(nseq, cbind(pow, pow2, powNull)*100, type = "s", ylim = c(0, 100),
##         lty = 1, col = cols, ylab = bquote("Pr(BF"["01"] < 1/.(1/k) * " )"),
##         xlab = bquote("Sample size per group" ~ italic(n)), lwd = 1.5,
##         yaxt = "n",
##         panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
## axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
## abline(v = nex, col = transpblack)
## axis(side = 4, at = power*100, labels = paste0(power*100, "%"), las = 1,
##      col = transpblack, cex.axis = 0.8)
## axis(side = 3, at = nex, col = transpblack, cex.axis = 0.8)
## abline(h = power*100, col = transpblack)
## legend("right",
##        legend = c("Point design prior", "Normal design prior", "Null hypothesis"),
##        lty = 1, lwd = 1.5, col = cols, bg = "white", cex = 0.7)
@


A complication in power and sample size calculations based on the Bayes
factor~\eqref{eq:tBF} is that it is not available in closed-form but requires
numerical evaluation of the integral in the denominator. Perhaps for this
reason, so far power and sample size have been computed using simulation. To
compute the power for a given sample size without simulation, we propose to use
the following two-step procedure instead:

\begin{enumerate}
  \item For a given sample size $n$ and analysis prior (specified with the
        parameters $\mu, \tau, \kappa, a, b$), use numerical root-finding to
        determine the `success region' $S$ in terms of $t$-statistics where the
        Bayes factor is equal or below the threshold $k$, i.e.,
        $S = \{t : \mathrm{BF}_{01} \leq k\}$. For a two-sided test, $S$ is
        typically a region specified by two critical values
        \mbox{$S = (-\infty, t_{\mathrm{crit}-}] \cup [t_{\mathrm{crit}+}, +\infty)$}.
        % while for one-sided tests there is typically only one critical value as
        % $S$ is just one interval, e.g., $S = [t_{\mathrm{crit}}, +\infty)$ for a
        % test in positive direction.

  \item For a given design prior, compute the probability of obtaining a
        $t$-statistic included in $S$. For example, based on a normal design
        prior $\theta \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d})$ and assuming a
        two-sample test with equally sized groups and that the data variance
        $\sigma^{2}$ is known, we have that approximately
        \mbox{$t \mid n, \mu_{d}, \tau_{d} \sim \mathrm{N}\{\mu_{d}\sqrt{n/2}, 1 + (n\tau^{2})/2\}$},
        hence the power can be computed by
  \begin{align*}
    \Pr\left(\mathrm{BF}_{01} \leq k \mid n, \mu_{d}, \tau_{d} \right)
    % = \Phi\left(\frac{t_{\mathrm{crit}-}/\sqrt{n/2} - \mu_{d}}{\sqrt{\tau^{2}_{d} + 2/n}}\right)
    % + \Phi\left(\frac{\mu_{d} - t_{\mathrm{crit}+}/\sqrt{n/2}}{\sqrt{\tau^{2}_{d} + 2/n}}\right).
    = \Phi\left(\frac{t_{\mathrm{crit}-} - \mu_{d}\sqrt{n/2}}{\sqrt{1 + (n\tau^{2}_{d})/2}}\right)
    + \Phi\left(\frac{\mu_{d}\sqrt{n/2} - t_{\mathrm{crit}+}}{\sqrt{1 + (n\tau^{2}_{d})/2}}\right).
  \end{align*}
\end{enumerate}

To calculate a sample size that ensures a certain target power, we can again use
numerical root-finding. To illustrate this, we now revisit the example from
\citet{Schoenbrodt2017} which was already re-analyzed in
Section~\ref{sec:schoenbrodtexample} with a normal analysis prior. We now
specify the analysis parameters
$\mu = 0, \tau = 1/\sqrt{2}, \kappa = 1, a = 0, b = +\infty$, i.e., a one-sided
JZS Bayes factor with scale $1/\sqrt{2}$ \citep{Wetzels2009}, as in the original
analysis. Using the previously described iterative approach, we calculate that a
sample size of \mbox{$n = \Sexpr{nex[1]}$} is required under a point design
prior at $\mu_{d} = \Sexpr{dpm}$ to achieve a target power of
\Sexpr{round(power*100)}\%. This differs only slightly from the simulation-based
$n = 146$ reported by \citet{Schoenbrodt2017}, possibly due to Monte Carlo
error.
% The root-finding approach is, however, substantially faster than the Monte
% Carlo approach. That is, computing the sample size for the previous example
% with root-finding as implemented in our package (function
% \texttt{powertbf01}), takes about 100 milliseconds, while the simulation based
% approach takes about 10 minutes.

<< >>=
## microbenchmark::microbenchmark({
##     powertbf01(k = 1/6, power = 0.95, null = 0, plocation = 0, pscale = 1/sqrt(2),
##                pdf = 1, alternative = "greater", dpm = 0.5, dpsd = 0)
## })
## ##> + Unit: milliseconds
## ##>       min       lq     mean   median       uq      max neval
## ##>  83.67747 85.16477 92.08307 88.00866 98.46287 117.2702   100
@

\subsection{Normal moment priors}
Nonlocal priors are prior distributions that have no probability density/mass at
the null value. They were introduced to allow evidence for the null to
accumulate more quickly if it is indeed true \citep{Johnson2010}. A convenient
class of nonlocal priors are normal moment priors, which have a density of the
form
$\mathrm{NM}(\theta \mid \theta_{0}, \tau) = \mathrm{N}(\theta \mid \theta_{0}, \tau^{2}) \times (\theta - \theta_{0})^{2}/\tau^{2}$
with location $\theta_{0}$ and spread $\tau$. Figure~\ref{fig:nonlocal} shows
three examples of normal moment priors. We see that the distributions have a
density of zero at the null value $\theta_{0} = 0$, encoding the assumption that
the null is the least likely parameter value under the alternative. Normal
moment priors have two modes at $\pm \tau \sqrt{2}$, which gives a convenient
way to elicit a prior, as $\tau$ may, for example, be set so that the mode
equals two parameter values deemed most plausible under the alternative.
\begin{figure}[!htb]
<< "moment-priors-illustration-plot", fig.height = 3.5 >>=
dnmoment <- function(x, location = 0, spread = 1) {
    stats::dnorm(x = x, mean = location, sd = spread)*(x - location)^2/spread^2
}
xseq <- seq(-4, 4, length.out = 500)
taus <- c(0.5, 1, 2)
null <- 0
dens <- sapply(X = taus, FUN = function(tau) dnmoment(x = xseq, location = 0, spread = tau))
cols <- hcl.colors(n = length(taus), alpha = 0.8)
par(mar = c(4, 5, 2, 2))
matplot(xseq, dens, type = "l", lty = 1, col = cols, lwd = 1.5,
        xlab = bquote("Parameter" ~ theta), ylab = "Density", las = 1,
        panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)))
leg <- sapply(taus, function(tau) as.expression(bquote({"NM("* theta[0] == "0,"} * tau == .(tau) * ")")))
legend("topright", legend = leg, col = cols, lty = 1, lwd = 1.5, cex = 0.7,
       bg = "white")
@
\caption{Illustration of a normal moment prior distribution for different spread
  parameters $\tau$. }
\label{fig:nonlocal}
\end{figure}

We will now extend power and sample size calculation to Bayes factors with
nonlocal moment analysis priors and normal design priors. The Bayes factor based
on a normally distributed parameter estimate
$\hat{\theta} \mid \theta \sim \mathrm{N}(\theta, \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n)$
that contrasts $H_{0} \colon \theta = \theta_{0}$ to
$H_{1} \colon \theta \neq \theta_{0}$ with prior
$\theta \mid H_{1} \sim \mathrm{NM}(\theta_{0}, \tau)$ assigned to $\theta$
under $H_{1}$ is given by
\begin{align}
  \label{eq:nlBF}
  \mathrm{BF}_{01} =
  \left(1 + \frac{n \tau^{2}}{\sigma^{2}_{\scriptscriptstyle \hat{\theta}}}\right)^{3/2}
  \, \exp\left[-\frac{1}{2} \frac{n(\hat{\theta} - \theta_{0})^{2}}{
  \sigma^{2}_{\scriptscriptstyle \hat{\theta}}\{1 + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/(n \tau^{2})\}}\right] \,
  \left[1 + \frac{n(\hat{\theta} - \theta_{0})^{2}}{
  \sigma^{2}_{\scriptscriptstyle \hat{\theta}}\{1 + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/(n \tau^{2})\}}\right]^{-1}
\end{align}
see e.g., \citet{Pramanik2024} or \citet{Pawel2023}. Under a normal design prior
\mbox{$\theta \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d})$}, the power to obtain a
Bayes factor below a threshold $k$ can then be expressed in closed-form
\begin{align}
  \label{eq:pnlBF}
  \Pr\left(\mathrm{BF}_{01} \leq k \mid n, \mu_{d}, \tau_{d}\right) =
  \Phi\left(-\sqrt{Y} - A\right) + \Phi\left(-\sqrt{Y} + A\right)
\end{align}
with
\begin{align*}
  &Y = \left(2 \mathrm{W}_{0}\left[\frac{\{1 + (n\tau^{2})/\sigma^{2}_{\scriptscriptstyle \hat{\theta}}\}^{3/2}\sqrt{e}}{2k}\right] - 1\right) \, \left\{\frac{1 + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/(n\tau^{2})}{1 + (n \tau^{2}_{d})/\sigma^{2}_{\scriptscriptstyle \hat{\theta}}} \right\}&
&\text{and}&
  &A = \frac{\mu_{d} - \theta_{0}}{\sqrt{\tau^{2}_{d} + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n}}&
\end{align*}
with $\mathrm{W}_{0}$ the principal branch of the Lambert W function, see
Appendix~\ref{app:nmprior} for details. Based on the power
function~\eqref{eq:pnlBF}, numerical root-finding can again be used to determine
the sample size such that a specified target power is achieved. Methods for
power and sample size calculations for normal moment prior Bayes factors are
both implemented in our R package (functions \texttt{nmbf01} and
\texttt{powernmbf01}).


\begin{figure}[!bt]
<< "normal-moment-example", fig.height = 6 >>=
## plot power curves for normal moment prior example
nseq <- seq(1, 1100, 1)
dpm <- 0.5
null <- 0
k <- 1/6
sd <- 2
psd <- 0.5/sqrt(2) # mode at 0.5
dpriors <- cbind(dpm = c(0.5, 0.5, 0), dpsd = c(0, 0.1, 0))
power <- 0.95
powH1 <- sapply(X = seq(1, nrow(dpriors)), FUN = function(i) {
    pnmbf01(k = k, n = nseq, sd = sd, null = null, psd = psd, dpm = dpriors[i,1],
            dpsd = dpriors[i,2])
})
powH0 <- sapply(X = seq(1, nrow(dpriors)), FUN = function(i) {
    pnmbf01(k = 1/k, n = nseq, sd = sd, null = null, psd = psd,
            dpm = dpriors[i,1], dpsd = dpriors[i,2], lower.tail = FALSE)
})
nH1 <- ceiling(sapply(X = c(1, 2), FUN = function(i) {
    nnmbf01(k = k, power = power,, sd = sd, null = null, psd = psd,
            dpm = dpriors[i,1], dpsd = dpriors[i,2])
}))
nH0 <- ceiling(sapply(X = 3, FUN = function(i) {
    nnmbf01(k = 1/k, power = power, sd = sd, null = null, psd = psd,
            dpm = dpriors[i,1], dpsd = dpriors[i,2], lower.tail = FALSE)
}))

par(mfrow = c(2, 1), mar = c(3, 5, 2.5, 2.5))
cols <- rev(palette.colors(n = 4, alpha = 0.95)[2:4])
transpblack <- adjustcolor(col = 1, alpha = 0.2)
matplot(nseq, powH1*100, lty = 1, type = "l", las = 1, ylim = c(0, 100),
        panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)),
        yaxt = "n", xlab = "",
        ylab = bquote("Pr(BF"["01"] < 1/.(1/k) * " )"), col = cols, lwd = 1.5)
axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
axis(side = 4, at = power*100, labels = paste0(power*100, "%"), las = 1,
     col = transpblack, cex.axis = 0.8)
axis(side = 3, at = nH1, col = transpblack, cex.axis = 0.8)
abline(v = nH1, col = transpblack)
abline(h = power*100, col = transpblack)
legend("right", bg = "white", title = "Design prior",
       legend = c(bquote("N(" * {mu[italic("d")] == .(dpriors[1,1])} * ", "
                         * tau[italic("d")] == .(dpriors[1,2]) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(dpriors[2,1])} * ", "
                         * tau[italic("d")] == .(dpriors[2,2]) * ")"),
                  bquote("N(" * {mu[italic("d")] == .(dpriors[3,1])} * ", "
                         * tau[italic("d")] == .(dpriors[3,2]) * ")")),
       lty = 1, lwd = 1.5, col = cols, cex = 0.7)
par(mar = c(4, 5, 1.5, 2.5))
matplot(nseq, powH0*100, lty = 1, type = "l", las = 1, ylim = c(0, 100),
        panel.first = grid(lty = 3, col = adjustcolor(col = 1, alpha = 0.1)),
        yaxt = "n", xlab = bquote("Sample size per group" ~ italic(n)),
        ylab = bquote("Pr(BF"["01"] > .(1/k) * " )"), col = cols, lwd = 1.5)
axis(side = 2, at = seq(0, 100, 20), labels = paste0(seq(0, 100, 20), "%"), las = 1)
axis(side = 4, at = power*100, labels = paste0(power*100, "%"), las = 1,
     col = transpblack, cex.axis = 0.8)
axis(side = 3, at = nH0, col = transpblack, cex.axis = 0.8)
abline(v = nH0, col = transpblack)
abline(h = power*100, col = transpblack)

## nH0 for normal analysis prior for comparison
nH0normal <- nbf01(k = 6, power = 0.95, sd = sqrt(2), null = 0, pm = 0,
                   psd = 1/sqrt(2), dpm = 0, dpsd = 0, lower.tail = FALSE)
@
\caption{Power and sample size calculations for standardized mean difference
  example from \citet{Schoenbrodt2017} based on normal moment prior Bayes
  factor. The normal moment analysis prior has modes at a medium effect size
  ($\tau = \Sexpr{psd*sqrt(2)}/\sqrt{2}$). The power is computed under either a
  point prior at a medium effect size (green), a normal prior that incorporates
  additional parameter uncertainty (blue), or under the null hypothesis
  (orange).}
\label{fig:nonlocalexample}
\end{figure}

Figure~\ref{fig:nonlocalexample} shows again power and sample size calculations
for the example from \citet{Schoenbrodt2017} considered earlier. This time,
however, we specify a normal moment analysis prior with modes at a medium
standardized mean difference effect size of $\theta = \pm 0.5$, which translates
to a prior spread parameter of $\tau = \Sexpr{psd*sqrt(2)}/\sqrt{2}$. Using the
same design priors as before, we can see that the sample sizes required to
achieve a target power of \Sexpr{round(power*100)}\% are larger than when using
the normal analysis prior as in Section~\ref{sec:schoenbrodtexample}. For
example, under the point design prior a sample size of $n = \Sexpr{nH1[1]}$ per
group is required while only $n = \Sexpr{n}$ were required with the normal
analysis prior (see Figure~\ref{fig:comparisonBFDA}). At the same time, the
sample size required to find evidence \emph{in favor} of the null hypothesis
with a target power of \Sexpr{round(power*100)}\% (bottom plot) is drastically
reduced ($n = \Sexpr{nH0}$) compared to the normal analysis prior
($n = \Sexpr{nH0normal}$). This is expected since the evidence for a true null
hypothesis accumulates faster with normal moment priors \citep{Johnson2010}.
% The design perspective allows data analysts to make an informed choice which
% of the two is more suitable for their aims and resources.

\section{Discussion}
\label{sec:discussion}
We presented methods for performing power and sample size calculations for the
situation when data are analyzed with Bayes factor hypothesis tests. These
methods rely on the approximate normality of parameter estimates (but not of the
underlying data), which is a common assumption underlying many methods for power
and sample size calculation. We have synthesized and extended previous
theoretical results on power functions for Bayes factors and implemented them in
an R package \texttt{bfpwr}. We also derived novel sample size formulas that are
easy-to-use, help fostering intuition, and enable understanding of theoretical
properties such as asymptotic power or (non-)existence of sample size for a
target power and design prior. Compared to commonly used simulation-based
methods, our methods are less general. However, in the setting where they are
applicable -- which includes many common scenarios, such as testing mean
differences -- they are faster, deterministic, and require no simulation
parameters to be specified. Therefore, we believe that the availability of such
methods addresses an important practical need and can help researchers design
efficient studies with minimal effort.

A clear limitation of our methodology is the asymptotic normality assumption.
This assumption may be inappropriate for certain data or parameter types, and
may lead to an underappreciation of uncertainty and consequently an
underestimation of sample size. Simulation-based methods do not have this
shortcoming, as they can be tailored to any data distribution and analysis
method. Nevertheless, simulation methods may be intimidating or too advanced for
research workers, in which case we believe it is better to do an approximate
calculation than no calculation at all. One avenue for future work might be to
extend closed-form power and sample size calculations to more specific settings
not considered here, such as, binary outcomes. Another limitation is the types
of Bayes factors that we considered for the analysis, which is limited to
univariate parameters with normal, normal moment, $t$, or point priors under the
alternative. Our work could be extended to ANOVA or regression settings with
multivariate parameters and/or to other prior distributions. We also did not
consider `open-ended' sequential designs, where data are collected continuously
until compelling evidence for one of the competing hypotheses is found
\citep{Wald1947}. The sequential approach is particularly attractive for Bayes
factor inference as design and analysis prior distributions can be updated based
on the accumulating data. Researchers can then make informed decisions about
whether or not it is worthwhile to continue collecting data or to stop
\citep{Stefan2022}. For these purposes, it would be interesting to consider the
Bayes factor indexed by the sample size as a stochastic process, and study its
properties. Finally, in situations where researchers have only a fixed sample
size at their disposal, it may be interesting to use a `reverse-Bayes' approach
\citep{Held2021b}. That is, one may `go backwards' and determine the design
prior required to achieve a desired target power. Researchers can then reason
whether or not this `reverse Bayes design prior' is scientifically plausible,
and whether or not they should undertake the study based on their limited
resources.


\section*{Acknowledgments}
We thank \anonymize{Angelika Stefan} and \anonymize{František Bartoš} for
valuable comments on drafts of the manuscript. The acknowledgment of these
individuals does not imply their endorsement of the paper.

\section*{Conflict of interest}
We declare no conflict of interest.

\section*{Software and data}
Code and data to reproduce our analyses are openly available at
\anonymize{\url{https://github.com/SamCH93/bfpwr}}. A snapshot of the repository
at the time of writing is available at
\anonymize{\url{https://doi.org/10.5281/zenodo.12582277}}. We used the
statistical programming language \Sexpr{R.Version()[["version.string"]]} for
analyses \citep{R} along with the \texttt{BFDA} \citep{Schoenbrodt2019},
\texttt{lamW} \citep{Adler2015}, \texttt{xtable} \citep{Dahl2019}, and
\texttt{knitr} \citep{Xie2024} packages.


\begin{appendices}


\section{The bfpwr R package}
\label{app:pkg}
Our R package
% can be installed by running \texttt{install.packages("bfpwr")} in an R
% session, the development version
can be installed from GitHub with the R command
\texttt{remotes::install\_github(repo = \anonymize{"SamCH93/bfpwr", subdir =
    "package"})} (requires the \texttt{remotes} package). We plan to submit the
package to CRAN in the near future. The workhorse function of our R package is
\texttt{powerbf01}. It is inspired by the \texttt{power.t.test} function from
the \texttt{stats} package, with which many user will be familiar. As
\texttt{power.t.test}, the function \texttt{powerbf01} assumes that the data are
continuous and that the parameter of interest is either a mean or a
(standardized) mean difference. The functions \texttt{pbf01} and \texttt{nbf01}
are more general and can be used for any approximately normally distributed
parameter estimate with approximate variance
$\mathrm{Var}(\hat{\theta}) = \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/n$,
although users have to specify the unit variance
$\sigma^{2}_{\scriptscriptstyle \hat{\theta}}$ themselves. Similar functions
exist also for $t$-test Bayes factors (\texttt{powertbf01}) and normal moment
prior Bayes factors (\texttt{powernmbf01}). The following code chunk illustrate
how \texttt{powerbf01} can be used.

\begin{spacing}{1}
<< "package-illustration", echo = TRUE, fig.height = 6 >>=
library(bfpwr)

## BF parameters
k <- 1/6 # BF threshold
null <- 0 # null value
sd <- 1 # standard deviation of one observation
pm <- null # analysis prior mean set to the null value
psd <- sqrt(2) # analysis prior sd set to sqrt(2)
type <- "two.sample" # two-sample test

## design prior
dpm <- 0.5 # design prior mean equal to large SMD effect size
dpsd <- 0.1 # design prior sd to incorporate parameter uncertainty

## determine sample size to achieve 85% power
power <- 0.85
ssd <- powerbf01(k = k, power = power, sd = sd, null = null, pm = pm, psd = psd,
                 dpm = dpm, dpsd = dpsd, type = type)
ssd

## plot power curve
plot(ssd, nlim = c(1, 400))
@
\end{spacing}

\section{Distribution of the Bayes factor}
\label{app:distributions}
The Bayes factor~\eqref{eq:BF01} with point analysis prior ($\tau = 0$) can be
rewritten as
\begin{align}
\label{eq:LRdesignform}
    \text{BF}_{01} 
    &= \exp\left[\frac{n}{\sigma^2_{\scriptscriptstyle \hat{\theta}}} \left\{\hat{\theta}(\theta_0 - \mu) - \frac{\theta_0^2 - \mu^2}{2}\right\}\right].
\end{align}
Suppose that compelling evidence for $H_1$ is achieved when
$\text{BF}_{01} \leq k$. In this case, $\text{BF}_{01} \leq k$ can be rewritten
as
\begin{align*}
    \hat{\theta}(\theta_0 - \mu) \leq \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}\log k}{n} + \frac{\theta_0^2 - \mu^2}{2}.
\end{align*}
Dividing by $(\theta_0 - \mu)$ changes the inequality if $\mu > \theta_0$. We
then have that under a normal distribution
$\hat{\theta} \mid n, \mu_{d}, \tau_{d} \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d} + \sigma^2_{\scriptscriptstyle \hat{\theta}}/n)$,
the probability of compelling evidence is given by~\eqref{eq:prLR}.

The Bayes factor~\eqref{eq:BF01} with normal analysis prior ($\tau > 0$) can
be rewritten as
\begin{align}
\label{eq:BFdesignform}
    \text{BF}_{01} 
    &= \sqrt{1 + \frac{n \tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}} \, \exp\left(-\frac{1}{2} \left[\frac{\{\hat{\theta} - \theta_0 - \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2}(\theta_0 - \mu)\}^2}{\frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n}(1 + \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2})} - \frac{(\theta_0 - \mu)^2}{\tau^2}\right]\right).
\end{align}
Suppose that compelling evidence for $H_1$ is achieved when
$\text{BF}_{01} \leq k$, which can be rearranged to
\begin{align*}
    \left\{\hat{\theta} - \theta_0 - \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2}(\theta_0 - \mu)\right\}^2 \geq
    \left\{\log\left(1 + \frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}\right) + \frac{(\theta_0 - \mu)^2}{\tau^2} - \log k^2\right\} \left(1 + \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2} \right) \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n}.
\end{align*}
Therefore, under a normal distribution
$\hat{\theta} \mid n, \mu_{d}, \tau_{d} \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d} + \sigma^2_{\scriptscriptstyle \hat{\theta}}/n)$,
the probability of compelling evidence is given by~\eqref{eq:prBF}.

\section{Limiting power of Bayes factor with normal analysis prior}
\label{app:asymptotics}
We have that
\begin{align*}
  \lim_{n\to \infty} M
  = \frac{\mu_{d} - \theta_{0}}{\tau_{d}}
\end{align*}
and
\begin{align*}
  \lim_{n\to \infty} X
  = \lim_{n \to \infty} \left[\left\{\log\left(1 + \frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}\right) + \frac{(\theta_0 - \mu)^2}{\tau^2} - \log k^2\right\}
  \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^{2}_{d} + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}}\right].
\end{align*}
Thus, when also $\tau_{d} \downarrow 0$ and $\mu_{d} \neq \theta_{0}$, both $M$
and $X$ diverge but the $M$ term diverges faster than the $X$ term. When
$\tau_{d} > 0$, the $M$ term approaches a constant while the $X$ term approaches
zero. Consequently, in both cases it holds that
\begin{align*}
  \lim_{n\to \infty}  \Pr(\text{BF}_{01} \leq k \mid n, \mu_{d} , \tau_{d}, \tau > 0)
  &= \lim_{n\to \infty} \left\{\Phi(-\sqrt{X} - M) + \Phi(-\sqrt{X} + M)\right\} %  \\
  % &= \lim_{n\to \infty} \left\{\Phi(-\sqrt{X} - M) + \Phi(-\sqrt{X} + M)\right\} \\
  = 1.
\end{align*}

\section{Sample size for Bayes factor with local normal prior}
\label{app:lambertWderiv}

Equating the power function~\eqref{eq:prBFcenter} to $1 - \beta$ and applying
algebraic manipulations, we have that
\begin{align*}
  z^{2}_{(1 - \beta)/2}
  &= \left\{\log\left(1 + \frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}\right) - \log k^2\right\} \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2} \\
  &\approx \left\{\log\left(\frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}}\right) - \log k^2\right\} \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2} \\
  &= \log\left(\frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}k^{2}}\right)  \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{n\tau^2}
\end{align*}
Multiplying by $-k^{2}$ and rewriting the second factor on the right-hand-side
as exponential leads to
\begin{align*}
 -k^{2} \, z^{2}_{(1 - \beta)/2}
  &= -\log\left(\frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}k^{2}}\right)   \exp\left\{-\log\left(\frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}k^{2}}\right) \right\}.
\end{align*}
Hence, we can apply the Lambert W function to obtain
\begin{align*}
  -\log\left(\frac{n\tau^2}{\sigma^2_{\scriptscriptstyle \hat{\theta}}k^{2}}\right)   = \mathrm{W}\left(-k^{2} \, z^{2}_{(1 - \beta)/2}\right)
\end{align*}
from which we get the sample size
\begin{align*}
 n = \frac{\sigma^2_{\scriptscriptstyle \hat{\theta}}}{\tau^{2}} \, k^{2} \, \exp \left\{ -\mathrm{W}\left(-k^{2} \, z^{2}_{(1 - \beta)/2}\right)\right\}.
\end{align*}
For arguments $y \in (-1/e, 0)$ , the Lambert W function has two branches. The
sample size is obtained from the branch commonly denoted as
$\mathrm{W}_{-1}(\cdot)$ which satisfies $\mathrm{W}(x) < -1$ for
$y \in (-1/e, 0)$ \citep{Corless1996}. This is because this branch always leads
to larger sample sizes than the other and guarantees that unit information
sample sizes are always larger than one.


\section{Power with normal moment prior}
\label{app:nmprior}

Setting the Bayes factor~\eqref{eq:nlBF} to less or equal than $k$ and applying
algebraic manipulations, we can bring the inequality into the form
\begin{align*}
  \exp\left[1 + \frac{n(\hat{\theta} - \theta_{0})^{2}}{
  \sigma^{2}_{\scriptscriptstyle \hat{\theta}}\{1 + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/(n \tau^{2})\}}\right] \,
  \left[1 + \frac{n(\hat{\theta} - \theta_{0})^{2}}{
  \sigma^{2}_{\scriptscriptstyle \hat{\theta}}\{1 + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/(n \tau^{2})\}}\right] \geq
  \frac{\{1 + (n\tau^{2})/\sigma^{2}_{\scriptscriptstyle \hat{\theta}}\}\sqrt{e}}{2k}.
\end{align*}
Applying the Lambert W function on both sides, leads to
\begin{align}
  \label{eq:powernmp2}
  1 + \frac{n(\hat{\theta} - \theta_{0})^{2}}{\sigma^{2}_{\scriptscriptstyle \hat{\theta}}\{1 + \sigma^{2}_{\scriptscriptstyle \hat{\theta}}/(n \tau^{2})\}} \geq
  \mathrm{W}_{0} \left[\frac{\{1 + (n\tau^{2})/\sigma^{2}_{\scriptscriptstyle \hat{\theta}}\}\sqrt{e}}{2k}\right].
\end{align}
Since the argument of the Lambert W function is real and always non-negative,
only the principal branch $\mathrm{W}_{0}$ can satisfy the inequality
\citep{Corless1996}. Assuming a
\mbox{$\hat{\theta} \mid n, \mu_{d}, \tau_{d} \sim \mathrm{N}(\mu_{d}, \tau^{2}_{d} + \sigma^2_{\scriptscriptstyle \hat{\theta}}/n)$}
distribution induced by a normal design prior, we can rearrange the
inequality~\eqref{eq:powernmp2} and obtain the power function~\eqref{eq:pnlBF}.


\end{appendices}

% Bibliography
% ======================================================================
\bibliographystyle{apalikedoiurl}
\bibliography{bibliography}

<< "sessionInfo1", eval = Reproducibility, results = "asis" >>=
## print R sessionInfo to see system information and package versions
## used to compile the manuscript (set Reproducibility = FALSE, to not do that)
cat("\\newpage \\section*{Computational details}")
@
<< "sessionInfo2", echo = Reproducibility, results = Reproducibility >>=
cat(paste(Sys.time(), Sys.timezone(), "\n"))
sessionInfo()
@

\end{document}
